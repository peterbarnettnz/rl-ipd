{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d324ff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from envs import MatrixGameEnv, MatrixGameEnv_no_history\n",
    "\n",
    "from players import TitForTatPlayer, TitForTatThenDefectPlayer\n",
    "\n",
    "import evaluation\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "38a002ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure(432x288)\n"
     ]
    }
   ],
   "source": [
    "plt.plot(np.random.randn(10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "125b1aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "from ray.rllib.examples.env.multi_agent import MultiAgentCartPole\n",
    "from ray.rllib.examples.models.shared_weights_model import \\\n",
    "    SharedWeightsModel1, SharedWeightsModel2, TF2SharedWeightsModel, \\\n",
    "    TorchSharedWeightsModel\n",
    "from ray.rllib.models import ModelCatalog\n",
    "# from ray.rllib.policy import PolicySpec\n",
    "from ray.rllib.utils.framework import try_import_tf\n",
    "from ray.rllib.utils.test_utils import check_learning_achieved\n",
    "from ray.tune.registry import register_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7949fc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 20:31:33,784\tINFO worker.py:810 -- Calling ray.init() again after it has already been called.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from ray.rllib.agents.ppo import DEFAULT_CONFIG as DEFAULT_CONFIG_PPO\n",
    "\n",
    "from ray.rllib.agents.dqn import DQNTrainer, DEFAULT_CONFIG \n",
    "from ray.rllib.agents.dqn import  DEFAULT_CONFIG as DEFAULT_CONFIG_DQN\n",
    "\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "ray.init(ignore_reinit_error=True, log_to_driver=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d89c84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "register_env('MG_t4td_env', lambda c: MatrixGameEnv(\n",
    "    player2=TitForTatThenDefectPlayer(min_defect_turn=0, max_defect_turn=100)))\n",
    "\n",
    "register_env('MG_t4t_env', lambda c: MatrixGameEnv(\n",
    "    player2=TitForTatPlayer()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a1e7d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/'\n",
    "exp_dir = 'DQN_single_t4td/'\n",
    "cp_path = \"/checkpoint_000100/checkpoint-100\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0660c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = os.listdir(base_dir+exp_dir)\n",
    "test_exp = exps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5de7c8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_dir = 'DQN_MG_t4t_env_3dc73_00000_0_gamma=0.999,lr=0.001,n_step=1_2021-08-13_15-33-36'\n",
    "run_dir = 'DQN_MG_t4t_env_3dc73_00001_1_gamma=0.99,lr=0.001,n_step=1_2021-08-13_15-33-36'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec7ec63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DQN_MG_t4td_env_f7859_00006_6_gamma=0.99,lr=0.0001,n_step=1_2021-08-13_15-31-39'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50b489e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path1 = base_dir+ exp_dir+test_exp\n",
    "with open(path1 + '/params.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5fc9db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 14:18:27,349\tINFO trainer.py:718 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2021-08-16 14:18:27,505\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "agent = DQNTrainer(config=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "988c40f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 14:18:27,594\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/DQN_single_t4td/DQN_MG_t4td_env_f7859_00006_6_gamma=0.99,lr=0.0001,n_step=1_2021-08-13_15-31-39/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 14:18:27,595\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 6167.652756929398, '_episodes_total': 1000}\n"
     ]
    }
   ],
   "source": [
    "agent.restore(path1+ cp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d57b4c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 14:18:27,600\tWARNING deprecation.py:33 -- DeprecationWarning: `compute_action` has been deprecated. Use `compute_single_action` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.compute_action(np.random.rand(400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "862b7cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.6904,), 0.3377)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation.is_t4t(agent, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "984b9ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.6755,), 0.3339)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation.is_t4t(agent, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0a2653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_agent = evaluation.test_random_agent(coop_frac=0.8)\n",
    "t4t_agent = evaluation.test_t4t_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4aec4fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.4966,), 0.8064)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation.is_t4t(rand_agent, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d68c634",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/'\n",
    "exp_dir = 'DQN_single_t4t/'\n",
    "exp_dir = 'DQN_single_t4td/'\n",
    "\n",
    "cp_path = \"/checkpoint_000100/checkpoint-100\"\n",
    "exps = os.listdir(base_dir+exp_dir)\n",
    "test_exp = exps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab807ce3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Unknown config parameter `use_critic` ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-897c7013c050>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/params.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQNTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath1\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mcp_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mt_frac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_frac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_t4t\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, env, logger_creator)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger_creator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         def _init(self, config: TrainerConfigDict,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, env, logger_creator)\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0mlogger_creator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_logger_creator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/tune/trainable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, logger_creator)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0msetup_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msetup_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mSETUP_TIME_THRESHOLD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# user-provided one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_user_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         self.config = Trainer.merge_trainer_configs(self._default_config,\n\u001b[0m\u001b[1;32m    693\u001b[0m                                                     config)\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\u001b[0m in \u001b[0;36mmerge_trainer_configs\u001b[0;34m(cls, config1, config2, _allow_unknown_configs)\u001b[0m\n\u001b[1;32m   1332\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_allow_unknown_configs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m             \u001b[0m_allow_unknown_configs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allow_unknown_configs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m         return deep_update(config1, config2, _allow_unknown_configs,\n\u001b[0m\u001b[1;32m   1335\u001b[0m                            \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allow_unknown_subkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m                            cls._override_all_subkeys_if_type_changes)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/tune/utils/util.py\u001b[0m in \u001b[0;36mdeep_update\u001b[0;34m(original, new_dict, new_keys_allowed, allow_new_subkey_list, override_all_if_type_changes)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnew_keys_allowed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown config parameter `{}` \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;31m# Both orginal value and new one are dicts.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Unknown config parameter `use_critic` "
     ]
    }
   ],
   "source": [
    "\n",
    "t4t_frac = []\n",
    "coop_frac = []\n",
    "for test_exp in exps:\n",
    "    path1 = base_dir+ exp_dir+test_exp\n",
    "# path1 = base_dir+ exp_dir+run_dir\n",
    "\n",
    "# path1='/home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/DQN_single_t4t'\n",
    "# path1='/home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/DQN_single_t4t/DQN_MG_t4t_env_3dc73_00000_0_gamma=0.999,lr=0.001,n_step=1_2021-08-13_15-33-36'\n",
    "    \n",
    "    if os.path.exists(path1 + cp_path):\n",
    "        with open(path1 + '/params.pkl', 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        agent = DQNTrainer(config=data)\n",
    "        agent.restore(path1+ cp_path, )\n",
    "        t_frac, c_frac = evaluation.is_t4t(agent,100)\n",
    "        t4t_frac.append(t_frac[0])\n",
    "        coop_frac.append(c_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d6c8e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['gamma', 'lr', 'n_step']\n",
    "data_names = ['episode_reward_max', 'episode_reward_min', 'episode_reward_mean']\n",
    "data1 = pd.DataFrame(columns=['ID']+attributes+data_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a8b0157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/'\n",
    "exp_dir = 'DQN_single_t4t/'\n",
    "env_pref = 'DQN_MG_t4t_env'\n",
    "\n",
    "# exp_dir = 'DQN_single_t4td/'\n",
    "# env_pref = 'DQN_MG_t4td_env'\n",
    "\n",
    "cp_path = \"/checkpoint_000100/checkpoint-100\"\n",
    "exps = os.listdir(base_dir+exp_dir)\n",
    "test_exp = exps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "798deffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 21:22:29,334\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:22:29,380\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/DQN_single_t4t/DQN_MG_t4t_env_3dc73_00000_0_gamma=0.999,lr=0.001,n_step=1_2021-08-13_15-33-36/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:22:29,383\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 5087.005356788635, '_episodes_total': 1000}\n",
      "2021-08-16 21:22:29,961\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:22:30,002\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/DQN_single_t4t/DQN_MG_t4t_env_3dc73_00000_0_gamma=0.999,lr=0.001,n_step=1_2021-08-13_15-33-36/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:22:30,004\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 5087.005356788635, '_episodes_total': 1000}\n",
      "2021-08-16 21:22:30,627\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:22:30,669\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/DQN_single_t4t/DQN_MG_t4t_env_3dc73_00000_0_gamma=0.999,lr=0.001,n_step=1_2021-08-13_15-33-36/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:22:30,670\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 5087.005356788635, '_episodes_total': 1000}\n",
      "2021-08-16 21:22:31,261\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:22:31,314\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/DQN_single_t4t/DQN_MG_t4t_env_3dc73_00001_1_gamma=0.99,lr=0.001,n_step=1_2021-08-13_15-33-36/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:22:31,315\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 5057.536703586578, '_episodes_total': 1000}\n",
      "2021-08-16 21:22:31,917\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:22:31,959\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/DQN_single_t4t/DQN_MG_t4t_env_3dc73_00001_1_gamma=0.99,lr=0.001,n_step=1_2021-08-13_15-33-36/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:22:31,960\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 5057.536703586578, '_episodes_total': 1000}\n",
      "2021-08-16 21:22:32,545\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:22:32,584\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/DQN_single_t4t/DQN_MG_t4t_env_3dc73_00001_1_gamma=0.99,lr=0.001,n_step=1_2021-08-13_15-33-36/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:22:32,585\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 5057.536703586578, '_episodes_total': 1000}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "re_dict = {}\n",
    "for attr in attributes:\n",
    "    p = re.compile(attr + '=[^_^,]*')\n",
    "    re_dict[attr] = p\n",
    "    \n",
    "data_names = ['episode_reward_max', 'episode_reward_min', 'episode_reward_mean']\n",
    "data1 = pd.DataFrame(columns=['ID']+attributes+data_names)\n",
    "\n",
    "for test_exp in exps:\n",
    "    \n",
    "    path1 = base_dir+ exp_dir+test_exp\n",
    "\n",
    "    if os.path.isdir(path1) and (env_pref in test_exp):\n",
    "#         print(filename)\n",
    "\n",
    "        append_dict = {}\n",
    "        append_dict['ID'] = test_exp\n",
    "        has_none = False\n",
    "        for attr in attributes:\n",
    "            p = re_dict[attr]\n",
    "            val_str = p.findall(test_exp)\n",
    "            if not val_str:\n",
    "                val = None\n",
    "#                 print(at)\n",
    "                has_none = True\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                val = val_str[0][len(attr)+1:]\n",
    "                val = float(val)\n",
    "            append_dict[attr] = val\n",
    "            if os.path.exists(path1 + cp_path):\n",
    "#                 print('hi')\n",
    "                progress_csv = pd.read_csv(path1+'/progress.csv')\n",
    "                \n",
    "                for data_name in data_names:\n",
    "                    vals = progress_csv[data_name].to_numpy()\n",
    "                    append_dict[data_name] = vals\n",
    "                    append_dict['final_' + data_name] = vals[-1]\n",
    "                    \n",
    "                with open(path1 + '/params.pkl', 'rb') as f:\n",
    "                    data = pickle.load(f)\n",
    "                agent = DQNTrainer(config=data)\n",
    "                agent.restore(path1+ cp_path, )\n",
    "                t_frac, c_frac = evaluation.is_t4t(agent,100)\n",
    "                \n",
    "                append_dict['t4t_frac'] = t_frac\n",
    "                append_dict['coop_frac'] = c_frac\n",
    "                \n",
    "            else:\n",
    "                has_none = True\n",
    "                break\n",
    "\n",
    "        if not has_none:\n",
    "            data1 = data1.append(append_dict,ignore_index=True)\n",
    "#             print(append_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "729a64d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>gamma</th>\n",
       "      <th>lr</th>\n",
       "      <th>n_step</th>\n",
       "      <th>episode_reward_max</th>\n",
       "      <th>episode_reward_min</th>\n",
       "      <th>episode_reward_mean</th>\n",
       "      <th>coop_frac</th>\n",
       "      <th>final_episode_reward_max</th>\n",
       "      <th>final_episode_reward_mean</th>\n",
       "      <th>final_episode_reward_min</th>\n",
       "      <th>t4t_frac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DQN_MG_t4t_env_3dc73_00000_0_gamma=0.999,lr=0....</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[239.0, 239.0, 261.0, 263.0, 273.0, 281.0, 282...</td>\n",
       "      <td>[219.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207...</td>\n",
       "      <td>[227.0, 223.0, 228.9, 233.875, 240.1, 245.5666...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>301.0</td>\n",
       "      <td>297.91</td>\n",
       "      <td>289.0</td>\n",
       "      <td>(0.5,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DQN_MG_t4t_env_3dc73_00001_1_gamma=0.99,lr=0.0...</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[259.0, 259.0, 259.0, 259.0, 259.0, 268.0, 276...</td>\n",
       "      <td>[206.0, 188.0, 176.0, 176.0, 166.0, 166.0, 166...</td>\n",
       "      <td>[230.1, 220.65, 213.5, 207.6, 202.16, 207.1666...</td>\n",
       "      <td>0.56</td>\n",
       "      <td>298.0</td>\n",
       "      <td>256.85</td>\n",
       "      <td>172.0</td>\n",
       "      <td>(0.53,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ID  gamma     lr  n_step  \\\n",
       "0  DQN_MG_t4t_env_3dc73_00000_0_gamma=0.999,lr=0....  0.999  0.001     1.0   \n",
       "1  DQN_MG_t4t_env_3dc73_00001_1_gamma=0.99,lr=0.0...  0.990  0.001     1.0   \n",
       "\n",
       "                                  episode_reward_max  \\\n",
       "0  [239.0, 239.0, 261.0, 263.0, 273.0, 281.0, 282...   \n",
       "1  [259.0, 259.0, 259.0, 259.0, 259.0, 268.0, 276...   \n",
       "\n",
       "                                  episode_reward_min  \\\n",
       "0  [219.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207...   \n",
       "1  [206.0, 188.0, 176.0, 176.0, 166.0, 166.0, 166...   \n",
       "\n",
       "                                 episode_reward_mean  coop_frac  \\\n",
       "0  [227.0, 223.0, 228.9, 233.875, 240.1, 245.5666...       1.00   \n",
       "1  [230.1, 220.65, 213.5, 207.6, 202.16, 207.1666...       0.56   \n",
       "\n",
       "   final_episode_reward_max  final_episode_reward_mean  \\\n",
       "0                     301.0                     297.91   \n",
       "1                     298.0                     256.85   \n",
       "\n",
       "   final_episode_reward_min t4t_frac  \n",
       "0                     289.0   (0.5,)  \n",
       "1                     172.0  (0.53,)  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f72e8be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_pickle(base_dir + exp_dir + 'data_save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3d1478c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>gamma</th>\n",
       "      <th>lr</th>\n",
       "      <th>n_step</th>\n",
       "      <th>episode_reward_max</th>\n",
       "      <th>episode_reward_min</th>\n",
       "      <th>episode_reward_mean</th>\n",
       "      <th>coop_frac</th>\n",
       "      <th>final_episode_reward_max</th>\n",
       "      <th>final_episode_reward_mean</th>\n",
       "      <th>final_episode_reward_min</th>\n",
       "      <th>t4t_frac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00006_6_gamma=0.99,lr=0....</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[210.0, 210.0, 220.0, 258.0, 258.0, 258.0, 264...</td>\n",
       "      <td>[69.0, 60.0, 60.0, 60.0, 34.0, 34.0, 34.0, 34....</td>\n",
       "      <td>[128.3, 127.7, 131.53333333333333, 137.525, 14...</td>\n",
       "      <td>0.32</td>\n",
       "      <td>261.0</td>\n",
       "      <td>187.97</td>\n",
       "      <td>103.0</td>\n",
       "      <td>(0.69,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00013_13_gamma=0.9,lr=5e...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[227.0, 227.0, 227.0, 227.0, 251.0, 251.0, 270...</td>\n",
       "      <td>[105.0, 58.0, 58.0, 58.0, 48.0, 48.0, 48.0, 48...</td>\n",
       "      <td>[158.0, 145.85, 131.6, 129.45, 136.84, 138.983...</td>\n",
       "      <td>0.56</td>\n",
       "      <td>276.0</td>\n",
       "      <td>192.04</td>\n",
       "      <td>101.0</td>\n",
       "      <td>(0.75,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00009_9_gamma=0.8,lr=0.0...</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[228.0, 230.0, 230.0, 246.0, 246.0, 246.0, 275...</td>\n",
       "      <td>[45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45....</td>\n",
       "      <td>[149.0, 146.15, 142.03333333333333, 141.675, 1...</td>\n",
       "      <td>0.52</td>\n",
       "      <td>292.0</td>\n",
       "      <td>205.26</td>\n",
       "      <td>100.0</td>\n",
       "      <td>(0.71,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00017_17_gamma=0.95,lr=1...</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[236.0, 236.0, 236.0, 236.0, 236.0, 236.0, 236...</td>\n",
       "      <td>[56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56....</td>\n",
       "      <td>[143.2, 159.4, 143.5, 137.85, 141.0, 138.91666...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>268.0</td>\n",
       "      <td>162.80</td>\n",
       "      <td>68.0</td>\n",
       "      <td>(0.65,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00036_36_gamma=0.99,lr=1...</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[221.0, 235.0, 235.0, 235.0, 235.0, 235.0, 235...</td>\n",
       "      <td>[64.0, 64.0, 57.0, 56.0, 56.0, 56.0, 56.0, 56....</td>\n",
       "      <td>[132.4, 136.85, 132.73333333333332, 136.1, 134...</td>\n",
       "      <td>0.67</td>\n",
       "      <td>286.0</td>\n",
       "      <td>170.49</td>\n",
       "      <td>66.0</td>\n",
       "      <td>(0.56,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00020_20_gamma=0.999,lr=...</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[230.0, 237.0, 237.0, 237.0, 240.0, 240.0, 240...</td>\n",
       "      <td>[47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47....</td>\n",
       "      <td>[117.4, 139.45, 150.8, 146.95, 147.86, 147.65,...</td>\n",
       "      <td>0.53</td>\n",
       "      <td>284.0</td>\n",
       "      <td>181.51</td>\n",
       "      <td>38.0</td>\n",
       "      <td>(0.62,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00001_1_gamma=0.99,lr=0....</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[238.0, 238.0, 238.0, 238.0, 238.0, 238.0, 238...</td>\n",
       "      <td>[55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55....</td>\n",
       "      <td>[170.0, 147.0, 144.53333333333333, 141.25, 141...</td>\n",
       "      <td>0.42</td>\n",
       "      <td>258.0</td>\n",
       "      <td>187.30</td>\n",
       "      <td>87.0</td>\n",
       "      <td>(0.58,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00011_11_gamma=0.99,lr=5...</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[217.0, 217.0, 217.0, 249.0, 249.0, 249.0, 252...</td>\n",
       "      <td>[83.0, 63.0, 45.0, 37.0, 30.0, 30.0, 30.0, 30....</td>\n",
       "      <td>[143.8, 140.7, 140.3, 143.875, 141.7, 141.9833...</td>\n",
       "      <td>0.32</td>\n",
       "      <td>253.0</td>\n",
       "      <td>194.95</td>\n",
       "      <td>98.0</td>\n",
       "      <td>(0.62,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00021_21_gamma=0.99,lr=0...</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[220.0, 227.0, 227.0, 227.0, 227.0, 253.0, 253...</td>\n",
       "      <td>[57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57....</td>\n",
       "      <td>[146.9, 148.5, 140.4, 138.65, 135.78, 141.1833...</td>\n",
       "      <td>0.62</td>\n",
       "      <td>288.0</td>\n",
       "      <td>194.29</td>\n",
       "      <td>81.0</td>\n",
       "      <td>(0.76,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00008_8_gamma=0.9,lr=0.0...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[238.0, 238.0, 238.0, 255.0, 255.0, 255.0, 255...</td>\n",
       "      <td>[62.0, 62.0, 62.0, 44.0, 41.0, 41.0, 38.0, 38....</td>\n",
       "      <td>[133.3, 139.25, 146.73333333333332, 147.125, 1...</td>\n",
       "      <td>0.55</td>\n",
       "      <td>293.0</td>\n",
       "      <td>199.58</td>\n",
       "      <td>102.0</td>\n",
       "      <td>(0.79,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00004_4_gamma=0.8,lr=0.0...</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[213.0, 214.0, 224.0, 224.0, 224.0, 230.0, 230...</td>\n",
       "      <td>[87.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 76....</td>\n",
       "      <td>[123.5, 127.55, 135.43333333333334, 140.225, 1...</td>\n",
       "      <td>0.58</td>\n",
       "      <td>298.0</td>\n",
       "      <td>192.06</td>\n",
       "      <td>99.0</td>\n",
       "      <td>(0.77,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00039_39_gamma=0.8,lr=1e...</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[245.0, 245.0, 245.0, 245.0, 245.0, 252.0, 252...</td>\n",
       "      <td>[71.0, 71.0, 63.0, 63.0, 61.0, 59.0, 59.0, 53....</td>\n",
       "      <td>[148.8, 152.4, 145.9, 144.1, 140.34, 140.08333...</td>\n",
       "      <td>0.44</td>\n",
       "      <td>236.0</td>\n",
       "      <td>146.08</td>\n",
       "      <td>93.0</td>\n",
       "      <td>(0.59,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00018_18_gamma=0.9,lr=1e...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[217.0, 217.0, 222.0, 222.0, 222.0, 222.0, 222...</td>\n",
       "      <td>[85.0, 64.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59....</td>\n",
       "      <td>[139.8, 135.55, 134.5, 131.775, 129.22, 131.2,...</td>\n",
       "      <td>0.55</td>\n",
       "      <td>277.0</td>\n",
       "      <td>161.72</td>\n",
       "      <td>61.0</td>\n",
       "      <td>(0.53,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00037_37_gamma=0.95,lr=1...</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[238.0, 238.0, 238.0, 238.0, 238.0, 238.0, 238...</td>\n",
       "      <td>[98.0, 63.0, 63.0, 63.0, 57.0, 57.0, 54.0, 54....</td>\n",
       "      <td>[174.9, 155.4, 143.16666666666666, 145.15, 140...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>229.0</td>\n",
       "      <td>152.16</td>\n",
       "      <td>85.0</td>\n",
       "      <td>(0.63,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00010_10_gamma=0.999,lr=...</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[229.0, 231.0, 234.0, 259.0, 259.0, 259.0, 259...</td>\n",
       "      <td>[53.0, 53.0, 53.0, 50.0, 50.0, 46.0, 46.0, 46....</td>\n",
       "      <td>[123.7, 143.05, 145.0, 155.1, 152.56, 152.2, 1...</td>\n",
       "      <td>0.19</td>\n",
       "      <td>231.0</td>\n",
       "      <td>181.30</td>\n",
       "      <td>94.0</td>\n",
       "      <td>(0.53,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00026_26_gamma=0.99,lr=0...</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[194.0, 201.0, 223.0, 223.0, 250.0, 250.0, 264...</td>\n",
       "      <td>[64.0, 64.0, 64.0, 56.0, 56.0, 51.0, 51.0, 51....</td>\n",
       "      <td>[136.5, 139.75, 139.03333333333333, 136.675, 1...</td>\n",
       "      <td>0.29</td>\n",
       "      <td>280.0</td>\n",
       "      <td>188.28</td>\n",
       "      <td>104.0</td>\n",
       "      <td>(0.66,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00007_7_gamma=0.95,lr=0....</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[170.0, 197.0, 234.0, 234.0, 261.0, 270.0, 270...</td>\n",
       "      <td>[66.0, 61.0, 61.0, 41.0, 41.0, 41.0, 41.0, 41....</td>\n",
       "      <td>[101.5, 113.3, 123.8, 131.0, 136.68, 140.66666...</td>\n",
       "      <td>0.35</td>\n",
       "      <td>281.0</td>\n",
       "      <td>191.22</td>\n",
       "      <td>99.0</td>\n",
       "      <td>(0.72,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00003_3_gamma=0.9,lr=0.0...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[230.0, 230.0, 245.0, 248.0, 248.0, 248.0, 252...</td>\n",
       "      <td>[99.0, 75.0, 75.0, 70.0, 70.0, 70.0, 70.0, 70....</td>\n",
       "      <td>[149.2, 140.85, 152.0, 152.5, 156.68, 160.65, ...</td>\n",
       "      <td>0.37</td>\n",
       "      <td>296.0</td>\n",
       "      <td>200.81</td>\n",
       "      <td>88.0</td>\n",
       "      <td>(0.75,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00029_29_gamma=0.8,lr=0....</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[204.0, 229.0, 229.0, 229.0, 229.0, 229.0, 229...</td>\n",
       "      <td>[57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57....</td>\n",
       "      <td>[137.0, 143.85, 136.93333333333334, 137.125, 1...</td>\n",
       "      <td>0.23</td>\n",
       "      <td>206.0</td>\n",
       "      <td>152.00</td>\n",
       "      <td>101.0</td>\n",
       "      <td>(0.54,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00025_25_gamma=0.999,lr=...</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[203.0, 225.0, 225.0, 225.0, 227.0, 251.0, 251...</td>\n",
       "      <td>[59.0, 58.0, 58.0, 58.0, 50.0, 50.0, 50.0, 50....</td>\n",
       "      <td>[140.1, 129.8, 124.7, 126.325, 130.18, 133.45,...</td>\n",
       "      <td>0.58</td>\n",
       "      <td>298.0</td>\n",
       "      <td>201.79</td>\n",
       "      <td>78.0</td>\n",
       "      <td>(0.73,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00027_27_gamma=0.95,lr=0...</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[195.0, 226.0, 237.0, 237.0, 237.0, 237.0, 237...</td>\n",
       "      <td>[85.0, 69.0, 64.0, 64.0, 64.0, 55.0, 55.0, 55....</td>\n",
       "      <td>[139.5, 149.1, 148.36666666666667, 145.2, 141....</td>\n",
       "      <td>0.29</td>\n",
       "      <td>209.0</td>\n",
       "      <td>155.70</td>\n",
       "      <td>103.0</td>\n",
       "      <td>(0.47,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00035_35_gamma=0.999,lr=...</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[191.0, 206.0, 219.0, 228.0, 228.0, 228.0, 228...</td>\n",
       "      <td>[64.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54....</td>\n",
       "      <td>[124.6, 130.15, 133.7, 135.025, 133.86, 137.13...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>118.0</td>\n",
       "      <td>105.48</td>\n",
       "      <td>99.0</td>\n",
       "      <td>(0.45,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00024_24_gamma=0.8,lr=0....</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[206.0, 235.0, 235.0, 235.0, 235.0, 235.0, 267...</td>\n",
       "      <td>[82.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56....</td>\n",
       "      <td>[157.5, 149.35, 154.63333333333333, 152.075, 1...</td>\n",
       "      <td>0.35</td>\n",
       "      <td>219.0</td>\n",
       "      <td>158.10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>(0.57,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00031_31_gamma=0.99,lr=5...</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[230.0, 234.0, 234.0, 247.0, 263.0, 263.0, 269...</td>\n",
       "      <td>[60.0, 60.0, 53.0, 44.0, 44.0, 44.0, 44.0, 44....</td>\n",
       "      <td>[156.4, 156.85, 147.2, 142.95, 149.68, 150.883...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>281.0</td>\n",
       "      <td>191.39</td>\n",
       "      <td>97.0</td>\n",
       "      <td>(0.75,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00012_12_gamma=0.95,lr=5...</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[256.0, 256.0, 256.0, 256.0, 256.0, 256.0, 256...</td>\n",
       "      <td>[66.0, 57.0, 57.0, 48.0, 48.0, 48.0, 48.0, 36....</td>\n",
       "      <td>[177.8, 155.85, 155.76666666666668, 148.575, 1...</td>\n",
       "      <td>0.49</td>\n",
       "      <td>271.0</td>\n",
       "      <td>181.72</td>\n",
       "      <td>97.0</td>\n",
       "      <td>(0.69,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00034_34_gamma=0.8,lr=5e...</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[241.0, 241.0, 241.0, 241.0, 241.0, 241.0, 241...</td>\n",
       "      <td>[79.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54....</td>\n",
       "      <td>[164.0, 158.15, 157.03333333333333, 151.975, 1...</td>\n",
       "      <td>0.21</td>\n",
       "      <td>218.0</td>\n",
       "      <td>159.92</td>\n",
       "      <td>106.0</td>\n",
       "      <td>(0.56,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00030_30_gamma=0.999,lr=...</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[221.0, 221.0, 221.0, 224.0, 269.0, 269.0, 269...</td>\n",
       "      <td>[75.0, 68.0, 58.0, 58.0, 42.0, 42.0, 42.0, 42....</td>\n",
       "      <td>[150.3, 143.1, 139.26666666666668, 142.0, 144....</td>\n",
       "      <td>0.94</td>\n",
       "      <td>297.0</td>\n",
       "      <td>179.65</td>\n",
       "      <td>40.0</td>\n",
       "      <td>(0.5,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00022_22_gamma=0.95,lr=0...</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[224.0, 224.0, 224.0, 224.0, 224.0, 245.0, 246...</td>\n",
       "      <td>[78.0, 78.0, 78.0, 76.0, 76.0, 76.0, 76.0, 76....</td>\n",
       "      <td>[165.0, 165.2, 166.96666666666667, 158.075, 15...</td>\n",
       "      <td>0.39</td>\n",
       "      <td>287.0</td>\n",
       "      <td>176.03</td>\n",
       "      <td>98.0</td>\n",
       "      <td>(0.59,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00023_23_gamma=0.9,lr=0....</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[207.0, 207.0, 236.0, 236.0, 236.0, 236.0, 236...</td>\n",
       "      <td>[62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62....</td>\n",
       "      <td>[128.6, 114.8, 125.73333333333332, 135.025, 13...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>247.0</td>\n",
       "      <td>176.74</td>\n",
       "      <td>99.0</td>\n",
       "      <td>(0.45,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00032_32_gamma=0.95,lr=5...</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[206.0, 234.0, 234.0, 234.0, 234.0, 234.0, 234...</td>\n",
       "      <td>[63.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50....</td>\n",
       "      <td>[135.7, 131.6, 124.5, 130.1, 129.08, 125.68333...</td>\n",
       "      <td>0.23</td>\n",
       "      <td>275.0</td>\n",
       "      <td>140.80</td>\n",
       "      <td>104.0</td>\n",
       "      <td>(0.57,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00016_16_gamma=0.99,lr=1...</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[181.0, 216.0, 216.0, 216.0, 216.0, 216.0, 216...</td>\n",
       "      <td>[70.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55....</td>\n",
       "      <td>[112.7, 125.55, 131.73333333333332, 132.875, 1...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>279.0</td>\n",
       "      <td>163.25</td>\n",
       "      <td>41.0</td>\n",
       "      <td>(0.6,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00015_15_gamma=0.999,lr=...</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[223.0, 225.0, 233.0, 233.0, 233.0, 233.0, 233...</td>\n",
       "      <td>[68.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48....</td>\n",
       "      <td>[135.4, 132.8, 140.73333333333332, 138.175, 13...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>116.0</td>\n",
       "      <td>104.90</td>\n",
       "      <td>97.0</td>\n",
       "      <td>(0.5,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00038_38_gamma=0.9,lr=1e...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[229.0, 229.0, 229.0, 229.0, 229.0, 237.0, 237...</td>\n",
       "      <td>[53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53....</td>\n",
       "      <td>[174.6, 160.35, 152.13333333333333, 147.975, 1...</td>\n",
       "      <td>0.34</td>\n",
       "      <td>232.0</td>\n",
       "      <td>153.25</td>\n",
       "      <td>88.0</td>\n",
       "      <td>(0.61,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00002_2_gamma=0.95,lr=0....</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[224.0, 224.0, 235.0, 235.0, 251.0, 251.0, 273...</td>\n",
       "      <td>[51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51....</td>\n",
       "      <td>[134.3, 133.7, 135.5, 135.825, 144.58, 150.966...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>290.0</td>\n",
       "      <td>192.61</td>\n",
       "      <td>99.0</td>\n",
       "      <td>(0.76,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00000_0_gamma=0.999,lr=0...</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[163.0, 213.0, 213.0, 235.0, 235.0, 235.0, 251...</td>\n",
       "      <td>[63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63....</td>\n",
       "      <td>[121.0, 122.5, 131.8, 138.925, 146.6, 149.0666...</td>\n",
       "      <td>0.55</td>\n",
       "      <td>260.0</td>\n",
       "      <td>152.81</td>\n",
       "      <td>41.0</td>\n",
       "      <td>(0.41,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00005_5_gamma=0.999,lr=0...</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[243.0, 243.0, 243.0, 243.0, 243.0, 243.0, 243...</td>\n",
       "      <td>[85.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 43....</td>\n",
       "      <td>[150.8, 146.45, 143.33333333333334, 139.475, 1...</td>\n",
       "      <td>0.42</td>\n",
       "      <td>228.0</td>\n",
       "      <td>189.02</td>\n",
       "      <td>72.0</td>\n",
       "      <td>(0.6,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00014_14_gamma=0.8,lr=5e...</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[213.0, 216.0, 238.0, 238.0, 254.0, 255.0, 255...</td>\n",
       "      <td>[79.0, 68.0, 68.0, 67.0, 67.0, 56.0, 50.0, 50....</td>\n",
       "      <td>[154.7, 149.45, 149.06666666666666, 148.225, 1...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>286.0</td>\n",
       "      <td>206.05</td>\n",
       "      <td>101.0</td>\n",
       "      <td>(0.74,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00033_33_gamma=0.9,lr=5e...</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[216.0, 221.0, 221.0, 241.0, 251.0, 251.0, 251...</td>\n",
       "      <td>[115.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54...</td>\n",
       "      <td>[171.8, 153.6, 153.7, 153.6, 156.34, 157.68333...</td>\n",
       "      <td>0.26</td>\n",
       "      <td>234.0</td>\n",
       "      <td>133.20</td>\n",
       "      <td>100.0</td>\n",
       "      <td>(0.7,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00019_19_gamma=0.8,lr=1e...</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[175.0, 204.0, 207.0, 223.0, 223.0, 223.0, 223...</td>\n",
       "      <td>[54.0, 54.0, 54.0, 54.0, 54.0, 50.0, 50.0, 50....</td>\n",
       "      <td>[127.0, 133.75, 136.96666666666667, 139.65, 14...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>266.0</td>\n",
       "      <td>175.97</td>\n",
       "      <td>79.0</td>\n",
       "      <td>(0.59,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>DQN_MG_t4td_env_f7859_00028_28_gamma=0.9,lr=0....</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[210.0, 210.0, 232.0, 240.0, 240.0, 240.0, 240...</td>\n",
       "      <td>[79.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50....</td>\n",
       "      <td>[141.4, 133.5, 152.56666666666666, 151.0, 153....</td>\n",
       "      <td>0.39</td>\n",
       "      <td>242.0</td>\n",
       "      <td>156.08</td>\n",
       "      <td>100.0</td>\n",
       "      <td>(0.53,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   ID  gamma       lr  n_step  \\\n",
       "0   DQN_MG_t4td_env_f7859_00006_6_gamma=0.99,lr=0....  0.990  0.00010     1.0   \n",
       "1   DQN_MG_t4td_env_f7859_00013_13_gamma=0.9,lr=5e...  0.900  0.00005     1.0   \n",
       "2   DQN_MG_t4td_env_f7859_00009_9_gamma=0.8,lr=0.0...  0.800  0.00010     1.0   \n",
       "3   DQN_MG_t4td_env_f7859_00017_17_gamma=0.95,lr=1...  0.950  0.00001     1.0   \n",
       "4   DQN_MG_t4td_env_f7859_00036_36_gamma=0.99,lr=1...  0.990  0.00001     5.0   \n",
       "5   DQN_MG_t4td_env_f7859_00020_20_gamma=0.999,lr=...  0.999  0.00100     5.0   \n",
       "6   DQN_MG_t4td_env_f7859_00001_1_gamma=0.99,lr=0....  0.990  0.00100     1.0   \n",
       "7   DQN_MG_t4td_env_f7859_00011_11_gamma=0.99,lr=5...  0.990  0.00005     1.0   \n",
       "8   DQN_MG_t4td_env_f7859_00021_21_gamma=0.99,lr=0...  0.990  0.00100     5.0   \n",
       "9   DQN_MG_t4td_env_f7859_00008_8_gamma=0.9,lr=0.0...  0.900  0.00010     1.0   \n",
       "10  DQN_MG_t4td_env_f7859_00004_4_gamma=0.8,lr=0.0...  0.800  0.00100     1.0   \n",
       "11  DQN_MG_t4td_env_f7859_00039_39_gamma=0.8,lr=1e...  0.800  0.00001     5.0   \n",
       "12  DQN_MG_t4td_env_f7859_00018_18_gamma=0.9,lr=1e...  0.900  0.00001     1.0   \n",
       "13  DQN_MG_t4td_env_f7859_00037_37_gamma=0.95,lr=1...  0.950  0.00001     5.0   \n",
       "14  DQN_MG_t4td_env_f7859_00010_10_gamma=0.999,lr=...  0.999  0.00005     1.0   \n",
       "15  DQN_MG_t4td_env_f7859_00026_26_gamma=0.99,lr=0...  0.990  0.00010     5.0   \n",
       "16  DQN_MG_t4td_env_f7859_00007_7_gamma=0.95,lr=0....  0.950  0.00010     1.0   \n",
       "17  DQN_MG_t4td_env_f7859_00003_3_gamma=0.9,lr=0.0...  0.900  0.00100     1.0   \n",
       "18  DQN_MG_t4td_env_f7859_00029_29_gamma=0.8,lr=0....  0.800  0.00010     5.0   \n",
       "19  DQN_MG_t4td_env_f7859_00025_25_gamma=0.999,lr=...  0.999  0.00010     5.0   \n",
       "20  DQN_MG_t4td_env_f7859_00027_27_gamma=0.95,lr=0...  0.950  0.00010     5.0   \n",
       "21  DQN_MG_t4td_env_f7859_00035_35_gamma=0.999,lr=...  0.999  0.00001     5.0   \n",
       "22  DQN_MG_t4td_env_f7859_00024_24_gamma=0.8,lr=0....  0.800  0.00100     5.0   \n",
       "23  DQN_MG_t4td_env_f7859_00031_31_gamma=0.99,lr=5...  0.990  0.00005     5.0   \n",
       "24  DQN_MG_t4td_env_f7859_00012_12_gamma=0.95,lr=5...  0.950  0.00005     1.0   \n",
       "25  DQN_MG_t4td_env_f7859_00034_34_gamma=0.8,lr=5e...  0.800  0.00005     5.0   \n",
       "26  DQN_MG_t4td_env_f7859_00030_30_gamma=0.999,lr=...  0.999  0.00005     5.0   \n",
       "27  DQN_MG_t4td_env_f7859_00022_22_gamma=0.95,lr=0...  0.950  0.00100     5.0   \n",
       "28  DQN_MG_t4td_env_f7859_00023_23_gamma=0.9,lr=0....  0.900  0.00100     5.0   \n",
       "29  DQN_MG_t4td_env_f7859_00032_32_gamma=0.95,lr=5...  0.950  0.00005     5.0   \n",
       "30  DQN_MG_t4td_env_f7859_00016_16_gamma=0.99,lr=1...  0.990  0.00001     1.0   \n",
       "31  DQN_MG_t4td_env_f7859_00015_15_gamma=0.999,lr=...  0.999  0.00001     1.0   \n",
       "32  DQN_MG_t4td_env_f7859_00038_38_gamma=0.9,lr=1e...  0.900  0.00001     5.0   \n",
       "33  DQN_MG_t4td_env_f7859_00002_2_gamma=0.95,lr=0....  0.950  0.00100     1.0   \n",
       "34  DQN_MG_t4td_env_f7859_00000_0_gamma=0.999,lr=0...  0.999  0.00100     1.0   \n",
       "35  DQN_MG_t4td_env_f7859_00005_5_gamma=0.999,lr=0...  0.999  0.00010     1.0   \n",
       "36  DQN_MG_t4td_env_f7859_00014_14_gamma=0.8,lr=5e...  0.800  0.00005     1.0   \n",
       "37  DQN_MG_t4td_env_f7859_00033_33_gamma=0.9,lr=5e...  0.900  0.00005     5.0   \n",
       "38  DQN_MG_t4td_env_f7859_00019_19_gamma=0.8,lr=1e...  0.800  0.00001     1.0   \n",
       "39  DQN_MG_t4td_env_f7859_00028_28_gamma=0.9,lr=0....  0.900  0.00010     5.0   \n",
       "\n",
       "                                   episode_reward_max  \\\n",
       "0   [210.0, 210.0, 220.0, 258.0, 258.0, 258.0, 264...   \n",
       "1   [227.0, 227.0, 227.0, 227.0, 251.0, 251.0, 270...   \n",
       "2   [228.0, 230.0, 230.0, 246.0, 246.0, 246.0, 275...   \n",
       "3   [236.0, 236.0, 236.0, 236.0, 236.0, 236.0, 236...   \n",
       "4   [221.0, 235.0, 235.0, 235.0, 235.0, 235.0, 235...   \n",
       "5   [230.0, 237.0, 237.0, 237.0, 240.0, 240.0, 240...   \n",
       "6   [238.0, 238.0, 238.0, 238.0, 238.0, 238.0, 238...   \n",
       "7   [217.0, 217.0, 217.0, 249.0, 249.0, 249.0, 252...   \n",
       "8   [220.0, 227.0, 227.0, 227.0, 227.0, 253.0, 253...   \n",
       "9   [238.0, 238.0, 238.0, 255.0, 255.0, 255.0, 255...   \n",
       "10  [213.0, 214.0, 224.0, 224.0, 224.0, 230.0, 230...   \n",
       "11  [245.0, 245.0, 245.0, 245.0, 245.0, 252.0, 252...   \n",
       "12  [217.0, 217.0, 222.0, 222.0, 222.0, 222.0, 222...   \n",
       "13  [238.0, 238.0, 238.0, 238.0, 238.0, 238.0, 238...   \n",
       "14  [229.0, 231.0, 234.0, 259.0, 259.0, 259.0, 259...   \n",
       "15  [194.0, 201.0, 223.0, 223.0, 250.0, 250.0, 264...   \n",
       "16  [170.0, 197.0, 234.0, 234.0, 261.0, 270.0, 270...   \n",
       "17  [230.0, 230.0, 245.0, 248.0, 248.0, 248.0, 252...   \n",
       "18  [204.0, 229.0, 229.0, 229.0, 229.0, 229.0, 229...   \n",
       "19  [203.0, 225.0, 225.0, 225.0, 227.0, 251.0, 251...   \n",
       "20  [195.0, 226.0, 237.0, 237.0, 237.0, 237.0, 237...   \n",
       "21  [191.0, 206.0, 219.0, 228.0, 228.0, 228.0, 228...   \n",
       "22  [206.0, 235.0, 235.0, 235.0, 235.0, 235.0, 267...   \n",
       "23  [230.0, 234.0, 234.0, 247.0, 263.0, 263.0, 269...   \n",
       "24  [256.0, 256.0, 256.0, 256.0, 256.0, 256.0, 256...   \n",
       "25  [241.0, 241.0, 241.0, 241.0, 241.0, 241.0, 241...   \n",
       "26  [221.0, 221.0, 221.0, 224.0, 269.0, 269.0, 269...   \n",
       "27  [224.0, 224.0, 224.0, 224.0, 224.0, 245.0, 246...   \n",
       "28  [207.0, 207.0, 236.0, 236.0, 236.0, 236.0, 236...   \n",
       "29  [206.0, 234.0, 234.0, 234.0, 234.0, 234.0, 234...   \n",
       "30  [181.0, 216.0, 216.0, 216.0, 216.0, 216.0, 216...   \n",
       "31  [223.0, 225.0, 233.0, 233.0, 233.0, 233.0, 233...   \n",
       "32  [229.0, 229.0, 229.0, 229.0, 229.0, 237.0, 237...   \n",
       "33  [224.0, 224.0, 235.0, 235.0, 251.0, 251.0, 273...   \n",
       "34  [163.0, 213.0, 213.0, 235.0, 235.0, 235.0, 251...   \n",
       "35  [243.0, 243.0, 243.0, 243.0, 243.0, 243.0, 243...   \n",
       "36  [213.0, 216.0, 238.0, 238.0, 254.0, 255.0, 255...   \n",
       "37  [216.0, 221.0, 221.0, 241.0, 251.0, 251.0, 251...   \n",
       "38  [175.0, 204.0, 207.0, 223.0, 223.0, 223.0, 223...   \n",
       "39  [210.0, 210.0, 232.0, 240.0, 240.0, 240.0, 240...   \n",
       "\n",
       "                                   episode_reward_min  \\\n",
       "0   [69.0, 60.0, 60.0, 60.0, 34.0, 34.0, 34.0, 34....   \n",
       "1   [105.0, 58.0, 58.0, 58.0, 48.0, 48.0, 48.0, 48...   \n",
       "2   [45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45....   \n",
       "3   [56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56....   \n",
       "4   [64.0, 64.0, 57.0, 56.0, 56.0, 56.0, 56.0, 56....   \n",
       "5   [47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47....   \n",
       "6   [55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55....   \n",
       "7   [83.0, 63.0, 45.0, 37.0, 30.0, 30.0, 30.0, 30....   \n",
       "8   [57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57....   \n",
       "9   [62.0, 62.0, 62.0, 44.0, 41.0, 41.0, 38.0, 38....   \n",
       "10  [87.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 76....   \n",
       "11  [71.0, 71.0, 63.0, 63.0, 61.0, 59.0, 59.0, 53....   \n",
       "12  [85.0, 64.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59....   \n",
       "13  [98.0, 63.0, 63.0, 63.0, 57.0, 57.0, 54.0, 54....   \n",
       "14  [53.0, 53.0, 53.0, 50.0, 50.0, 46.0, 46.0, 46....   \n",
       "15  [64.0, 64.0, 64.0, 56.0, 56.0, 51.0, 51.0, 51....   \n",
       "16  [66.0, 61.0, 61.0, 41.0, 41.0, 41.0, 41.0, 41....   \n",
       "17  [99.0, 75.0, 75.0, 70.0, 70.0, 70.0, 70.0, 70....   \n",
       "18  [57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57....   \n",
       "19  [59.0, 58.0, 58.0, 58.0, 50.0, 50.0, 50.0, 50....   \n",
       "20  [85.0, 69.0, 64.0, 64.0, 64.0, 55.0, 55.0, 55....   \n",
       "21  [64.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54....   \n",
       "22  [82.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56....   \n",
       "23  [60.0, 60.0, 53.0, 44.0, 44.0, 44.0, 44.0, 44....   \n",
       "24  [66.0, 57.0, 57.0, 48.0, 48.0, 48.0, 48.0, 36....   \n",
       "25  [79.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54....   \n",
       "26  [75.0, 68.0, 58.0, 58.0, 42.0, 42.0, 42.0, 42....   \n",
       "27  [78.0, 78.0, 78.0, 76.0, 76.0, 76.0, 76.0, 76....   \n",
       "28  [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62....   \n",
       "29  [63.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50....   \n",
       "30  [70.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55....   \n",
       "31  [68.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48....   \n",
       "32  [53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53....   \n",
       "33  [51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51....   \n",
       "34  [63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63....   \n",
       "35  [85.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 43....   \n",
       "36  [79.0, 68.0, 68.0, 67.0, 67.0, 56.0, 50.0, 50....   \n",
       "37  [115.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54...   \n",
       "38  [54.0, 54.0, 54.0, 54.0, 54.0, 50.0, 50.0, 50....   \n",
       "39  [79.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50....   \n",
       "\n",
       "                                  episode_reward_mean  coop_frac  \\\n",
       "0   [128.3, 127.7, 131.53333333333333, 137.525, 14...       0.32   \n",
       "1   [158.0, 145.85, 131.6, 129.45, 136.84, 138.983...       0.56   \n",
       "2   [149.0, 146.15, 142.03333333333333, 141.675, 1...       0.52   \n",
       "3   [143.2, 159.4, 143.5, 137.85, 141.0, 138.91666...       0.60   \n",
       "4   [132.4, 136.85, 132.73333333333332, 136.1, 134...       0.67   \n",
       "5   [117.4, 139.45, 150.8, 146.95, 147.86, 147.65,...       0.53   \n",
       "6   [170.0, 147.0, 144.53333333333333, 141.25, 141...       0.42   \n",
       "7   [143.8, 140.7, 140.3, 143.875, 141.7, 141.9833...       0.32   \n",
       "8   [146.9, 148.5, 140.4, 138.65, 135.78, 141.1833...       0.62   \n",
       "9   [133.3, 139.25, 146.73333333333332, 147.125, 1...       0.55   \n",
       "10  [123.5, 127.55, 135.43333333333334, 140.225, 1...       0.58   \n",
       "11  [148.8, 152.4, 145.9, 144.1, 140.34, 140.08333...       0.44   \n",
       "12  [139.8, 135.55, 134.5, 131.775, 129.22, 131.2,...       0.55   \n",
       "13  [174.9, 155.4, 143.16666666666666, 145.15, 140...       0.48   \n",
       "14  [123.7, 143.05, 145.0, 155.1, 152.56, 152.2, 1...       0.19   \n",
       "15  [136.5, 139.75, 139.03333333333333, 136.675, 1...       0.29   \n",
       "16  [101.5, 113.3, 123.8, 131.0, 136.68, 140.66666...       0.35   \n",
       "17  [149.2, 140.85, 152.0, 152.5, 156.68, 160.65, ...       0.37   \n",
       "18  [137.0, 143.85, 136.93333333333334, 137.125, 1...       0.23   \n",
       "19  [140.1, 129.8, 124.7, 126.325, 130.18, 133.45,...       0.58   \n",
       "20  [139.5, 149.1, 148.36666666666667, 145.2, 141....       0.29   \n",
       "21  [124.6, 130.15, 133.7, 135.025, 133.86, 137.13...       0.04   \n",
       "22  [157.5, 149.35, 154.63333333333333, 152.075, 1...       0.35   \n",
       "23  [156.4, 156.85, 147.2, 142.95, 149.68, 150.883...       0.60   \n",
       "24  [177.8, 155.85, 155.76666666666668, 148.575, 1...       0.49   \n",
       "25  [164.0, 158.15, 157.03333333333333, 151.975, 1...       0.21   \n",
       "26  [150.3, 143.1, 139.26666666666668, 142.0, 144....       0.94   \n",
       "27  [165.0, 165.2, 166.96666666666667, 158.075, 15...       0.39   \n",
       "28  [128.6, 114.8, 125.73333333333332, 135.025, 13...       0.25   \n",
       "29  [135.7, 131.6, 124.5, 130.1, 129.08, 125.68333...       0.23   \n",
       "30  [112.7, 125.55, 131.73333333333332, 132.875, 1...       0.75   \n",
       "31  [135.4, 132.8, 140.73333333333332, 138.175, 13...       0.08   \n",
       "32  [174.6, 160.35, 152.13333333333333, 147.975, 1...       0.34   \n",
       "33  [134.3, 133.7, 135.5, 135.825, 144.58, 150.966...       0.45   \n",
       "34  [121.0, 122.5, 131.8, 138.925, 146.6, 149.0666...       0.55   \n",
       "35  [150.8, 146.45, 143.33333333333334, 139.475, 1...       0.42   \n",
       "36  [154.7, 149.45, 149.06666666666666, 148.225, 1...       0.59   \n",
       "37  [171.8, 153.6, 153.7, 153.6, 156.34, 157.68333...       0.26   \n",
       "38  [127.0, 133.75, 136.96666666666667, 139.65, 14...       0.59   \n",
       "39  [141.4, 133.5, 152.56666666666666, 151.0, 153....       0.39   \n",
       "\n",
       "    final_episode_reward_max  final_episode_reward_mean  \\\n",
       "0                      261.0                     187.97   \n",
       "1                      276.0                     192.04   \n",
       "2                      292.0                     205.26   \n",
       "3                      268.0                     162.80   \n",
       "4                      286.0                     170.49   \n",
       "5                      284.0                     181.51   \n",
       "6                      258.0                     187.30   \n",
       "7                      253.0                     194.95   \n",
       "8                      288.0                     194.29   \n",
       "9                      293.0                     199.58   \n",
       "10                     298.0                     192.06   \n",
       "11                     236.0                     146.08   \n",
       "12                     277.0                     161.72   \n",
       "13                     229.0                     152.16   \n",
       "14                     231.0                     181.30   \n",
       "15                     280.0                     188.28   \n",
       "16                     281.0                     191.22   \n",
       "17                     296.0                     200.81   \n",
       "18                     206.0                     152.00   \n",
       "19                     298.0                     201.79   \n",
       "20                     209.0                     155.70   \n",
       "21                     118.0                     105.48   \n",
       "22                     219.0                     158.10   \n",
       "23                     281.0                     191.39   \n",
       "24                     271.0                     181.72   \n",
       "25                     218.0                     159.92   \n",
       "26                     297.0                     179.65   \n",
       "27                     287.0                     176.03   \n",
       "28                     247.0                     176.74   \n",
       "29                     275.0                     140.80   \n",
       "30                     279.0                     163.25   \n",
       "31                     116.0                     104.90   \n",
       "32                     232.0                     153.25   \n",
       "33                     290.0                     192.61   \n",
       "34                     260.0                     152.81   \n",
       "35                     228.0                     189.02   \n",
       "36                     286.0                     206.05   \n",
       "37                     234.0                     133.20   \n",
       "38                     266.0                     175.97   \n",
       "39                     242.0                     156.08   \n",
       "\n",
       "    final_episode_reward_min t4t_frac  \n",
       "0                      103.0  (0.69,)  \n",
       "1                      101.0  (0.75,)  \n",
       "2                      100.0  (0.71,)  \n",
       "3                       68.0  (0.65,)  \n",
       "4                       66.0  (0.56,)  \n",
       "5                       38.0  (0.62,)  \n",
       "6                       87.0  (0.58,)  \n",
       "7                       98.0  (0.62,)  \n",
       "8                       81.0  (0.76,)  \n",
       "9                      102.0  (0.79,)  \n",
       "10                      99.0  (0.77,)  \n",
       "11                      93.0  (0.59,)  \n",
       "12                      61.0  (0.53,)  \n",
       "13                      85.0  (0.63,)  \n",
       "14                      94.0  (0.53,)  \n",
       "15                     104.0  (0.66,)  \n",
       "16                      99.0  (0.72,)  \n",
       "17                      88.0  (0.75,)  \n",
       "18                     101.0  (0.54,)  \n",
       "19                      78.0  (0.73,)  \n",
       "20                     103.0  (0.47,)  \n",
       "21                      99.0  (0.45,)  \n",
       "22                     100.0  (0.57,)  \n",
       "23                      97.0  (0.75,)  \n",
       "24                      97.0  (0.69,)  \n",
       "25                     106.0  (0.56,)  \n",
       "26                      40.0   (0.5,)  \n",
       "27                      98.0  (0.59,)  \n",
       "28                      99.0  (0.45,)  \n",
       "29                     104.0  (0.57,)  \n",
       "30                      41.0   (0.6,)  \n",
       "31                      97.0   (0.5,)  \n",
       "32                      88.0  (0.61,)  \n",
       "33                      99.0  (0.76,)  \n",
       "34                      41.0  (0.41,)  \n",
       "35                      72.0   (0.6,)  \n",
       "36                     101.0  (0.74,)  \n",
       "37                     100.0   (0.7,)  \n",
       "38                      79.0  (0.59,)  \n",
       "39                     100.0  (0.53,)  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle(base_dir + exp_dir + 'data_save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "736727e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['gamma', 'lr']\n",
    "data_names = ['episode_reward_max', 'episode_reward_min', 'episode_reward_mean']\n",
    "data1 = pd.DataFrame(columns=['ID']+attributes+data_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0121b0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/'\n",
    "exp_dir = 'PPO_single_t4t/'\n",
    "env_pref = 'PPO_MG_t4t_env'\n",
    "\n",
    "exp_dir = 'PPO_single_t4td/'\n",
    "env_pref = 'PPO_MG_t4td_env'\n",
    "\n",
    "cp_path = \"/checkpoint_000100/checkpoint-100\"\n",
    "exps = os.listdir(base_dir+exp_dir)\n",
    "test_exp = exps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fee931be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 21:38:38,231\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:38:38,312\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00011_11_gamma=0.99,lr=5e-05_2021-08-14_10-03-08/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:38:38,315\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37253.41027712822, '_episodes_total': 4000}\n",
      "2021-08-16 21:38:45,019\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:38:45,093\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00011_11_gamma=0.99,lr=5e-05_2021-08-14_10-03-08/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:38:45,095\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37253.41027712822, '_episodes_total': 4000}\n",
      "2021-08-16 21:38:52,208\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:38:52,279\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00002_2_gamma=0.95,lr=0.001_2021-08-13_15-34-42/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:38:52,282\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 20193.482964277267, '_episodes_total': 4000}\n",
      "2021-08-16 21:38:58,603\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:38:58,694\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00002_2_gamma=0.95,lr=0.001_2021-08-13_15-34-42/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:38:58,696\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 20193.482964277267, '_episodes_total': 4000}\n",
      "2021-08-16 21:39:06,251\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:39:06,323\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00009_9_gamma=0.8,lr=0.0001_2021-08-14_05-32-13/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:39:06,328\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 13538.168478488922, '_episodes_total': 4000}\n",
      "2021-08-16 21:39:12,893\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:39:12,996\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00009_9_gamma=0.8,lr=0.0001_2021-08-14_05-32-13/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:39:13,007\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 13538.168478488922, '_episodes_total': 4000}\n",
      "2021-08-16 21:39:20,154\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:39:20,243\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00007_7_gamma=0.95,lr=0.0001_2021-08-13_23-40-14/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:39:20,244\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37804.59608960152, '_episodes_total': 4000}\n",
      "2021-08-16 21:39:26,676\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:39:26,755\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00007_7_gamma=0.95,lr=0.0001_2021-08-13_23-40-14/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:39:26,758\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37804.59608960152, '_episodes_total': 4000}\n",
      "2021-08-16 21:39:34,198\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:39:34,273\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00001_1_gamma=0.99,lr=0.001_2021-08-13_15-34-42/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:39:34,286\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 48024.91672992706, '_episodes_total': 4000}\n",
      "2021-08-16 21:39:42,436\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:39:42,559\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00001_1_gamma=0.99,lr=0.001_2021-08-13_15-34-42/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:39:42,562\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 48024.91672992706, '_episodes_total': 4000}\n",
      "2021-08-16 21:39:50,739\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:39:50,853\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00012_12_gamma=0.95,lr=5e-05_2021-08-14_11-22-22/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:39:50,858\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37393.647576093674, '_episodes_total': 4000}\n",
      "2021-08-16 21:39:58,400\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:39:58,508\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00012_12_gamma=0.95,lr=5e-05_2021-08-14_11-22-22/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:39:58,511\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37393.647576093674, '_episodes_total': 4000}\n",
      "2021-08-16 21:40:08,016\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:40:08,155\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00000_0_gamma=0.999,lr=0.001_2021-08-13_15-34-42/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:40:08,166\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 50240.8784327507, '_episodes_total': 4000}\n",
      "2021-08-16 21:40:15,587\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:40:15,683\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00000_0_gamma=0.999,lr=0.001_2021-08-13_15-34-42/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:40:15,701\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 50240.8784327507, '_episodes_total': 4000}\n",
      "2021-08-16 21:40:23,611\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:40:23,691\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00003_3_gamma=0.9,lr=0.001_2021-08-13_15-34-42/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:40:23,699\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 14681.821274757385, '_episodes_total': 4000}\n",
      "2021-08-16 21:40:30,930\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 21:40:31,035\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00003_3_gamma=0.9,lr=0.001_2021-08-13_15-34-42/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:40:31,057\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 14681.821274757385, '_episodes_total': 4000}\n",
      "2021-08-16 21:40:39,095\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:40:39,196\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00018_18_gamma=0.9,lr=1e-05_2021-08-15_02-31-18/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:40:39,198\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 36423.88321900368, '_episodes_total': 4000}\n",
      "2021-08-16 21:40:47,077\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:40:47,172\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00018_18_gamma=0.9,lr=1e-05_2021-08-15_02-31-18/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:40:47,174\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 36423.88321900368, '_episodes_total': 4000}\n",
      "2021-08-16 21:40:54,852\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:40:54,935\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00008_8_gamma=0.9,lr=0.0001_2021-08-14_04-55-17/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:40:54,945\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37931.57509016991, '_episodes_total': 4000}\n",
      "2021-08-16 21:41:01,550\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:41:01,632\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00008_8_gamma=0.9,lr=0.0001_2021-08-14_04-55-17/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:41:01,633\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37931.57509016991, '_episodes_total': 4000}\n",
      "2021-08-16 21:41:09,020\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:41:09,127\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00006_6_gamma=0.99,lr=0.0001_2021-08-13_21-11-25/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:41:09,129\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37362.994451761246, '_episodes_total': 4000}\n",
      "2021-08-16 21:41:16,060\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:41:16,156\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00006_6_gamma=0.99,lr=0.0001_2021-08-13_21-11-25/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:41:16,159\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37362.994451761246, '_episodes_total': 4000}\n",
      "2021-08-16 21:41:23,739\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:41:23,823\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00019_19_gamma=0.8,lr=1e-05_2021-08-15_06-54-03/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:41:23,834\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 36308.42251253128, '_episodes_total': 4000}\n",
      "2021-08-16 21:41:30,357\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:41:30,446\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00019_19_gamma=0.8,lr=1e-05_2021-08-15_06-54-03/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:41:30,464\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 36308.42251253128, '_episodes_total': 4000}\n",
      "2021-08-16 21:41:38,370\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:41:38,454\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00014_14_gamma=0.8,lr=5e-05_2021-08-14_16-04-36/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:41:38,459\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37609.4625210762, '_episodes_total': 4000}\n",
      "2021-08-16 21:41:45,090\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:41:45,164\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00014_14_gamma=0.8,lr=5e-05_2021-08-14_16-04-36/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:41:45,166\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37609.4625210762, '_episodes_total': 4000}\n",
      "2021-08-16 21:41:52,773\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:41:52,850\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00005_5_gamma=0.999,lr=0.0001_2021-08-13_19-39-33/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:41:52,853\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37495.59412121773, '_episodes_total': 4000}\n",
      "2021-08-16 21:42:00,455\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:42:00,572\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00005_5_gamma=0.999,lr=0.0001_2021-08-13_19-39-33/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:42:00,575\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37495.59412121773, '_episodes_total': 4000}\n",
      "2021-08-16 21:42:09,088\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:42:09,201\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00015_15_gamma=0.999,lr=1e-05_2021-08-14_20-27-02/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:42:09,203\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 36689.12459254265, '_episodes_total': 4000}\n",
      "2021-08-16 21:42:16,170\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:42:16,271\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00015_15_gamma=0.999,lr=1e-05_2021-08-14_20-27-02/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:42:16,278\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 36689.12459254265, '_episodes_total': 4000}\n",
      "2021-08-16 21:42:24,811\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:42:24,907\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00004_4_gamma=0.8,lr=0.001_2021-08-13_15-34-42/checkpoint_000100/checkpoint-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 21:42:24,910\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 14429.500284671783, '_episodes_total': 4000}\n",
      "2021-08-16 21:42:32,992\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:42:33,103\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00004_4_gamma=0.8,lr=0.001_2021-08-13_15-34-42/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:42:33,104\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 14429.500284671783, '_episodes_total': 4000}\n",
      "2021-08-16 21:42:40,934\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:42:41,029\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00010_10_gamma=0.999,lr=5e-05_2021-08-14_07-36-33/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:42:41,033\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37422.37003350258, '_episodes_total': 4000}\n",
      "2021-08-16 21:42:48,254\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:42:48,340\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00010_10_gamma=0.999,lr=5e-05_2021-08-14_07-36-33/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:42:48,342\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37422.37003350258, '_episodes_total': 4000}\n",
      "2021-08-16 21:42:58,112\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:42:58,219\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00013_13_gamma=0.9,lr=5e-05_2021-08-14_15-25-32/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:42:58,222\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37590.19506239891, '_episodes_total': 4000}\n",
      "2021-08-16 21:43:05,316\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:43:05,395\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00013_13_gamma=0.9,lr=5e-05_2021-08-14_15-25-32/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:43:05,396\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37590.19506239891, '_episodes_total': 4000}\n",
      "2021-08-16 21:43:13,812\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:43:13,903\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00016_16_gamma=0.99,lr=1e-05_2021-08-14_21-43-27/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:43:13,949\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 36860.704191207886, '_episodes_total': 4000}\n",
      "2021-08-16 21:43:21,214\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:43:21,292\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00016_16_gamma=0.99,lr=1e-05_2021-08-14_21-43-27/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:43:21,293\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 36860.704191207886, '_episodes_total': 4000}\n",
      "2021-08-16 21:43:29,274\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:43:29,361\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00017_17_gamma=0.95,lr=1e-05_2021-08-15_01-48-57/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:43:29,367\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 36935.077880859375, '_episodes_total': 4000}\n",
      "2021-08-16 21:43:36,389\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 21:43:36,484\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00017_17_gamma=0.95,lr=1e-05_2021-08-15_01-48-57/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 21:43:36,486\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 36935.077880859375, '_episodes_total': 4000}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "re_dict = {}\n",
    "for attr in attributes:\n",
    "    p = re.compile(attr + '=[^_^,]*')\n",
    "    re_dict[attr] = p\n",
    "    \n",
    "data_names = ['episode_reward_max', 'episode_reward_min', 'episode_reward_mean']\n",
    "data1 = pd.DataFrame(columns=['ID']+attributes+data_names)\n",
    "\n",
    "for test_exp in exps:\n",
    "    \n",
    "    path1 = base_dir+ exp_dir+test_exp\n",
    "\n",
    "    if os.path.isdir(path1) and (env_pref in test_exp):\n",
    "#         print(filename)\n",
    "\n",
    "        append_dict = {}\n",
    "        append_dict['ID'] = test_exp\n",
    "        has_none = False\n",
    "        for attr in attributes:\n",
    "            p = re_dict[attr]\n",
    "            val_str = p.findall(test_exp)\n",
    "            if not val_str:\n",
    "                val = None\n",
    "#                 print(at)\n",
    "                has_none = True\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                val = val_str[0][len(attr)+1:]\n",
    "                val = float(val)\n",
    "            append_dict[attr] = val\n",
    "            if os.path.exists(path1 + cp_path):\n",
    "#                 print('hi')\n",
    "                progress_csv = pd.read_csv(path1+'/progress.csv')\n",
    "                \n",
    "                for data_name in data_names:\n",
    "                    vals = progress_csv[data_name].to_numpy()\n",
    "                    append_dict[data_name] = vals\n",
    "                    append_dict['final_' + data_name] = vals[-1]\n",
    "                    \n",
    "                with open(path1 + '/params.pkl', 'rb') as f:\n",
    "                    data = pickle.load(f)\n",
    "                agent = PPOTrainer(config=data)\n",
    "                agent.restore(path1+ cp_path, )\n",
    "                t_frac, c_frac = evaluation.is_t4t(agent,100)\n",
    "                \n",
    "                append_dict['t4t_frac'] = t_frac\n",
    "                append_dict['coop_frac'] = c_frac\n",
    "                \n",
    "            else:\n",
    "                has_none = True\n",
    "                break\n",
    "\n",
    "        if not has_none:\n",
    "            data1 = data1.append(append_dict,ignore_index=True)\n",
    "#             print(append_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9913169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_pickle(base_dir + exp_dir + 'data_save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef501826",
   "metadata": {},
   "outputs": [],
   "source": [
    "t4t_frac_t4td = [0.73,\n",
    " 0.74,\n",
    " 0.66,\n",
    " 0.51,\n",
    " 0.56,\n",
    " 0.67,\n",
    " 0.58,\n",
    " 0.7,\n",
    " 0.66,\n",
    " 0.84,\n",
    " 0.77,\n",
    " 0.57,\n",
    " 0.55,\n",
    " 0.54,\n",
    " 0.63,\n",
    " 0.61,\n",
    " 0.75,\n",
    " 0.8,\n",
    " 0.47,\n",
    " 0.63,\n",
    " 0.44,\n",
    " 0.5,\n",
    " 0.5,\n",
    " 0.67,\n",
    " 0.58,\n",
    " 0.49,\n",
    " 0.63,\n",
    " 0.5,\n",
    " 0.37,\n",
    " 0.67,\n",
    " 0.54,\n",
    " 0.58,\n",
    " 0.55,\n",
    " 0.66,\n",
    " 0.44,\n",
    " 0.7,\n",
    " 0.78,\n",
    " 0.65,\n",
    " 0.6,\n",
    " 0.46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e23e076",
   "metadata": {},
   "outputs": [],
   "source": [
    "coop_frac_t4td = [0.38,\n",
    " 0.53,\n",
    " 0.48,\n",
    " 0.6,\n",
    " 0.75,\n",
    " 0.38,\n",
    " 0.43000000000000005,\n",
    " 0.42000000000000004,\n",
    " 0.6599999999999999,\n",
    " 0.37,\n",
    " 0.6699999999999999,\n",
    " 0.45999999999999996,\n",
    " 0.56,\n",
    " 0.45999999999999996,\n",
    " 0.21999999999999997,\n",
    " 0.29000000000000004,\n",
    " 0.38,\n",
    " 0.52,\n",
    " 0.25,\n",
    " 0.48,\n",
    " 0.16000000000000003,\n",
    " 0.020000000000000018,\n",
    " 0.44999999999999996,\n",
    " 0.6,\n",
    " 0.41000000000000003,\n",
    " 0.22999999999999998,\n",
    " 0.86,\n",
    " 0.5,\n",
    " 0.22999999999999998,\n",
    " 0.24,\n",
    " 0.8200000000000001,\n",
    " 0.030000000000000027,\n",
    " 0.44999999999999996,\n",
    " 0.37,\n",
    " 0.7,\n",
    " 0.44999999999999996,\n",
    " 0.55,\n",
    " 0.16000000000000003,\n",
    " 0.5,\n",
    " 0.36]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae264d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.607, 0.43450000000000005)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(t4t_frac_t4td), np.mean(coop_frac_t4td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e8e3de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.60175, 0.43149999999999994)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(t4t_frac), np.mean(coop_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae823b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f48f24e7a60>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure(432x288)\n"
     ]
    }
   ],
   "source": [
    "plt.plot(coop_frac, t4t_frac,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66c63428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 3., 6., 4., 6., 5., 6., 4., 3., 2.]),\n",
       " array([0.37 , 0.417, 0.464, 0.511, 0.558, 0.605, 0.652, 0.699, 0.746,\n",
       "        0.793, 0.84 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(t4t_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "143e195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/'\n",
    "exp_dir = 'PPO_single_t4t/'\n",
    "exp_dir = 'PPO_single_t4td/'\n",
    "\n",
    "cp_path = \"/checkpoint_000100/checkpoint-100\"\n",
    "exps = os.listdir(base_dir+exp_dir)\n",
    "test_exp = exps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "96b30ce2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 20:28:12,175\tINFO trainable.py:106 -- Trainable.setup took 11.679 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2021-08-16 20:28:12,184\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 20:28:12,334\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00011_11_gamma=0.99,lr=5e-05_2021-08-14_10-03-08/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 20:28:12,335\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37253.41027712822, '_episodes_total': 4000}\n",
      "2021-08-16 20:28:25,297\tINFO trainable.py:106 -- Trainable.setup took 12.109 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2021-08-16 20:28:25,322\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 20:28:25,587\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00002_2_gamma=0.95,lr=0.001_2021-08-13_15-34-42/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 20:28:25,595\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 20193.482964277267, '_episodes_total': 4000}\n",
      "2021-08-16 20:28:38,471\tINFO trainable.py:106 -- Trainable.setup took 12.182 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2021-08-16 20:28:38,493\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 20:28:38,591\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00009_9_gamma=0.8,lr=0.0001_2021-08-14_05-32-13/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 20:28:38,592\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 13538.168478488922, '_episodes_total': 4000}\n",
      "2021-08-16 20:28:49,294\tINFO trainable.py:106 -- Trainable.setup took 10.023 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2021-08-16 20:28:49,297\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 20:28:49,423\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00007_7_gamma=0.95,lr=0.0001_2021-08-13_23-40-14/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 20:28:49,426\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37804.59608960152, '_episodes_total': 4000}\n",
      "2021-08-16 20:28:58,225\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 20:28:58,348\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00001_1_gamma=0.99,lr=0.001_2021-08-13_15-34-42/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 20:28:58,350\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 48024.91672992706, '_episodes_total': 4000}\n",
      "2021-08-16 20:29:05,307\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 20:29:05,428\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00012_12_gamma=0.95,lr=5e-05_2021-08-14_11-22-22/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 20:29:05,444\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37393.647576093674, '_episodes_total': 4000}\n",
      "2021-08-16 20:29:12,481\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 20:29:12,587\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00000_0_gamma=0.999,lr=0.001_2021-08-13_15-34-42/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 20:29:12,588\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 50240.8784327507, '_episodes_total': 4000}\n",
      "2021-08-16 20:29:18,379\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 20:29:18,509\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00003_3_gamma=0.9,lr=0.001_2021-08-13_15-34-42/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 20:29:18,511\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 14681.821274757385, '_episodes_total': 4000}\n",
      "2021-08-16 20:29:25,084\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 20:29:25,184\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00018_18_gamma=0.9,lr=1e-05_2021-08-15_02-31-18/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 20:29:25,189\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 36423.88321900368, '_episodes_total': 4000}\n",
      "2021-08-16 20:29:31,621\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 20:29:31,781\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00008_8_gamma=0.9,lr=0.0001_2021-08-14_04-55-17/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 20:29:31,794\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37931.57509016991, '_episodes_total': 4000}\n",
      "2021-08-16 20:29:40,768\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 20:29:40,923\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00006_6_gamma=0.99,lr=0.0001_2021-08-13_21-11-25/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 20:29:40,932\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37362.994451761246, '_episodes_total': 4000}\n",
      "2021-08-16 20:29:47,943\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 20:29:48,062\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00019_19_gamma=0.8,lr=1e-05_2021-08-15_06-54-03/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 20:29:48,068\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 36308.42251253128, '_episodes_total': 4000}\n",
      "2021-08-16 20:29:54,538\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 20:29:54,677\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00014_14_gamma=0.8,lr=5e-05_2021-08-14_16-04-36/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 20:29:54,679\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37609.4625210762, '_episodes_total': 4000}\n",
      "2021-08-16 20:30:01,661\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 20:30:01,748\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00005_5_gamma=0.999,lr=0.0001_2021-08-13_19-39-33/checkpoint_000100/checkpoint-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 20:30:01,754\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37495.59412121773, '_episodes_total': 4000}\n",
      "2021-08-16 20:30:08,982\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 20:30:09,176\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00015_15_gamma=0.999,lr=1e-05_2021-08-14_20-27-02/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 20:30:09,204\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 36689.12459254265, '_episodes_total': 4000}\n",
      "2021-08-16 20:30:16,606\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 20:30:16,716\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00004_4_gamma=0.8,lr=0.001_2021-08-13_15-34-42/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 20:30:16,720\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 14429.500284671783, '_episodes_total': 4000}\n",
      "2021-08-16 20:30:23,887\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 20:30:24,063\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00010_10_gamma=0.999,lr=5e-05_2021-08-14_07-36-33/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 20:30:24,065\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37422.37003350258, '_episodes_total': 4000}\n",
      "2021-08-16 20:30:31,437\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 20:30:31,717\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00013_13_gamma=0.9,lr=5e-05_2021-08-14_15-25-32/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 20:30:31,723\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 37590.19506239891, '_episodes_total': 4000}\n",
      "2021-08-16 20:30:37,869\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 20:30:37,947\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00016_16_gamma=0.99,lr=1e-05_2021-08-14_21-43-27/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 20:30:37,950\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 36860.704191207886, '_episodes_total': 4000}\n",
      "2021-08-16 20:30:42,081\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2021-08-16 20:30:42,153\tINFO trainable.py:382 -- Restored on 192.168.1.21 from checkpoint: /home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/PPO_single_t4td/PPO_MG_t4td_env_65543_00017_17_gamma=0.95,lr=1e-05_2021-08-15_01-48-57/checkpoint_000100/checkpoint-100\n",
      "2021-08-16 20:30:42,155\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 36935.077880859375, '_episodes_total': 4000}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t4t_frac = []\n",
    "coop_frac = []\n",
    "for test_exp in exps:\n",
    "    path1 = base_dir+ exp_dir+test_exp\n",
    "# path1 = base_dir+ exp_dir+run_dir\n",
    "\n",
    "# path1='/home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/DQN_single_t4t'\n",
    "# path1='/home/peter/Documents/ML/rl_ipd/single_agent_runs1/new_runs/DQN_single_t4t/DQN_MG_t4t_env_3dc73_00000_0_gamma=0.999,lr=0.001,n_step=1_2021-08-13_15-33-36'\n",
    "    \n",
    "    if os.path.exists(path1 + cp_path):\n",
    "        with open(path1 + '/params.pkl', 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        agent = PPOTrainer(config=data)\n",
    "        agent.restore(path1+ cp_path, )\n",
    "        t_frac, c_frac = evaluation.is_t4t(agent,100)\n",
    "        t4t_frac.append(t_frac[0])\n",
    "        coop_frac.append(c_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "33d6f07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_options  = sorted(data1['lr'].unique())\n",
    "gamma_options = sorted(data1['gamma'].unique())\n",
    "\n",
    "ep_mean_arr = np.zeros((len(lr_options), len(gamma_options)))*np.nan\n",
    "\n",
    "for ii in range(len(data1)):\n",
    "    lr_i = lr_options.index(data1.loc[ii].lr)\n",
    "    \n",
    "    gamma_i = gamma_options.index(data1.loc[ii].gamma)\n",
    "        \n",
    "    ep_mean_arr[lr_i, gamma_i] = data1.loc[ii].final_episode_reward_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "25d17954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x7f46e887fa30>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure(432x288)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-17 00:05:06,403\tWARNING worker.py:1189 -- The autoscaler failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/peter/anaconda3/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 317, in run\n",
      "    self._run()\n",
      "  File \"/home/peter/anaconda3/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 207, in _run\n",
      "    self.update_load_metrics()\n",
      "  File \"/home/peter/anaconda3/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 169, in update_load_metrics\n",
      "    response = self.gcs_node_resources_stub.GetAllResourceUsage(\n",
      "  File \"/home/peter/.local/lib/python3.8/site-packages/grpc/_channel.py\", line 826, in __call__\n",
      "    return _end_unary_response_blocking(state, call, False, None)\n",
      "  File \"/home/peter/.local/lib/python3.8/site-packages/grpc/_channel.py\", line 729, in _end_unary_response_blocking\n",
      "    raise _InactiveRpcError(state)\n",
      "grpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\n",
      "\tstatus = StatusCode.DEADLINE_EXCEEDED\n",
      "\tdetails = \"Deadline Exceeded\"\n",
      "\tdebug_error_string = \"{\"created\":\"@1629115468.307953415\",\"description\":\"Error received from peer ipv4:192.168.1.21:41111\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1061,\"grpc_message\":\"Deadline Exceeded\",\"grpc_status\":4}\"\n",
      ">\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plt.pcolor(ep_mean_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "26a8c7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.46,\n",
       " 0.51,\n",
       " 0.46,\n",
       " 0.56,\n",
       " 0.49,\n",
       " 0.49,\n",
       " 0.57,\n",
       " 0.46,\n",
       " 0.52,\n",
       " 0.48,\n",
       " 0.43,\n",
       " 0.49,\n",
       " 0.42,\n",
       " 0.54,\n",
       " 0.55,\n",
       " 0.54,\n",
       " 0.51,\n",
       " 0.53,\n",
       " 0.52,\n",
       " 0.52]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4t_frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f97175df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.8,\n",
       " 0.56,\n",
       " 1.0,\n",
       " 0.6599999999999999,\n",
       " 1.0,\n",
       " 0.72,\n",
       " 0.71,\n",
       " 0.7,\n",
       " 0.52,\n",
       " 0.33999999999999997,\n",
       " 0.56,\n",
       " 1.0,\n",
       " 0.74,\n",
       " 0.5700000000000001,\n",
       " 0.6599999999999999,\n",
       " 0.76,\n",
       " 0.54]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coop_frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c1bc780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t4t_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c3af9bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure(432x288)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "plt.plot(t4t_frac)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e9bca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
