{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "from ray.rllib.examples.env.multi_agent import MultiAgentCartPole\n",
    "from ray.rllib.examples.env.multi_agent import M\n",
    "from ray.rllib.examples.models.shared_weights_model import \\\n",
    "    SharedWeightsModel1, SharedWeightsModel2, TF2SharedWeightsModel, \\\n",
    "    TorchSharedWeightsModel\n",
    "from ray.rllib.models import ModelCatalog\n",
    "# from ray.rllib.policy import PolicySpec\n",
    "from ray.rllib.utils.framework import try_import_tf\n",
    "from ray.rllib.utils.test_utils import check_learning_achieved\n",
    "from ray.tune.registry import register_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-26 11:27:40,526\tINFO services.py:1272 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.21',\n",
       " 'raylet_ip_address': '192.168.1.21',\n",
       " 'redis_address': '192.168.1.21:62372',\n",
       " 'object_store_address': '/tmp/ray/session_2021-07-26_11-27-39_274601_17352/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2021-07-26_11-27-39_274601_17352/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8266',\n",
       " 'session_dir': '/tmp/ray/session_2021-07-26_11-27-39_274601_17352',\n",
       " 'metrics_export_port': 58331,\n",
       " 'node_id': '02d2df6c6784ada8332246539d330396c4fd6ab8dae56c4fc32db879'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from ray.rllib.agents.ppo import DEFAULT_CONFIG as DEFAULT_CONFIG_PPO\n",
    "\n",
    "from ray.rllib.agents.dqn import DQNTrainer, DEFAULT_CONFIG \n",
    "from ray.rllib.agents.dqn import  DEFAULT_CONFIG as DEFAULT_CONFIG_DQN\n",
    "\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "ray.init(ignore_reinit_error=True, log_to_driver=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_AGENTS = 4\n",
    "\n",
    "\n",
    "\n",
    "config1 = {\n",
    "    \"env\":MultiAgentCartPole,\n",
    "    \"env_config\":{\n",
    "        \"num_agents\": NUM_AGENTS\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register_env(\"my_env\", lambda c: MultiAgentCartPole(config={\"num_agents\": 3}))\n",
    "register_env(\"my_env\", lambda c: )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config_ppo = DEFAULT_CONFIG_PPO.copy()\n",
    "# trainer_config_ppo[\"env_config\"] = {\"num_agents\": 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-26 11:35:11,762\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "trainer = PPOTrainer(trainer_config_ppo, env=\"my_env\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iteration 0...\n",
      "agent_timesteps_total: 4255\n",
      "custom_metrics: {}\n",
      "date: 2021-07-26_11-35-44\n",
      "done: false\n",
      "episode_len_mean: 32.766666666666666\n",
      "episode_media: {}\n",
      "episode_reward_max: 125.0\n",
      "episode_reward_mean: 67.8\n",
      "episode_reward_min: 38.0\n",
      "episodes_this_iter: 60\n",
      "episodes_total: 60\n",
      "experiment_id: 5776f46a7cb24475a8e539cc0ba24270\n",
      "hostname: coolo-computer\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6607719659805298\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.03300786018371582\n",
      "        model: {}\n",
      "        policy_loss: -0.04608149081468582\n",
      "        total_loss: 93.9007568359375\n",
      "        vf_explained_var: 0.07411719113588333\n",
      "        vf_loss: 93.94024658203125\n",
      "  num_agent_steps_sampled: 4255\n",
      "  num_agent_steps_trained: 4255\n",
      "  num_steps_sampled: 4255\n",
      "  num_steps_trained: 4255\n",
      "iterations_since_restore: 1\n",
      "node_ip: 192.168.1.21\n",
      "num_healthy_workers: 2\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 17.755319148936167\n",
      "  ram_util_percent: 65.30212765957448\n",
      "pid: 17352\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.059166845384534886\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07098105761197421\n",
      "  mean_inference_ms: 0.657028644592255\n",
      "  mean_raw_obs_processing_ms: 0.11441988663954454\n",
      "time_since_restore: 4.442423343658447\n",
      "time_this_iter_s: 4.442423343658447\n",
      "time_total_s: 4.442423343658447\n",
      "timers:\n",
      "  learn_throughput: 1232.836\n",
      "  learn_time_ms: 3451.391\n",
      "  load_throughput: 162969.259\n",
      "  load_time_ms: 26.109\n",
      "  sample_throughput: 4536.269\n",
      "  sample_time_ms: 937.996\n",
      "  update_time_ms: 2.151\n",
      "timestamp: 1627256144\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 4255\n",
      "training_iteration: 1\n",
      "\n",
      "Training iteration 1...\n",
      "agent_timesteps_total: 8304\n",
      "custom_metrics: {}\n",
      "date: 2021-07-26_11-35-48\n",
      "done: false\n",
      "episode_len_mean: 42.84615384615385\n",
      "episode_media: {}\n",
      "episode_reward_max: 251.0\n",
      "episode_reward_mean: 86.71428571428571\n",
      "episode_reward_min: 38.0\n",
      "episodes_this_iter: 31\n",
      "episodes_total: 91\n",
      "experiment_id: 5776f46a7cb24475a8e539cc0ba24270\n",
      "hostname: coolo-computer\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.30000001192092896\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.604378879070282\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.020337732508778572\n",
      "        model: {}\n",
      "        policy_loss: -0.02936127595603466\n",
      "        total_loss: 243.4742889404297\n",
      "        vf_explained_var: 0.12054198235273361\n",
      "        vf_loss: 243.49757385253906\n",
      "  num_agent_steps_sampled: 8304\n",
      "  num_agent_steps_trained: 8304\n",
      "  num_steps_sampled: 8304\n",
      "  num_steps_trained: 8304\n",
      "iterations_since_restore: 2\n",
      "node_ip: 192.168.1.21\n",
      "num_healthy_workers: 2\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.75\n",
      "  ram_util_percent: 65.44999999999999\n",
      "pid: 17352\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.05805103223565327\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06972155151022784\n",
      "  mean_inference_ms: 0.6427183590287885\n",
      "  mean_raw_obs_processing_ms: 0.1107912774840037\n",
      "time_since_restore: 8.442810535430908\n",
      "time_this_iter_s: 4.000387191772461\n",
      "time_total_s: 8.442810535430908\n",
      "timers:\n",
      "  learn_throughput: 1251.685\n",
      "  learn_time_ms: 3317.129\n",
      "  load_throughput: 307675.663\n",
      "  load_time_ms: 13.495\n",
      "  sample_throughput: 4753.067\n",
      "  sample_time_ms: 873.541\n",
      "  update_time_ms: 2.461\n",
      "timestamp: 1627256148\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 8304\n",
      "training_iteration: 2\n",
      "\n",
      "Training iteration 2...\n",
      "agent_timesteps_total: 13121\n",
      "custom_metrics: {}\n",
      "date: 2021-07-26_11-35-52\n",
      "done: false\n",
      "episode_len_mean: 57.01\n",
      "episode_media: {}\n",
      "episode_reward_max: 531.0\n",
      "episode_reward_mean: 116.69\n",
      "episode_reward_min: 38.0\n",
      "episodes_this_iter: 12\n",
      "episodes_total: 103\n",
      "experiment_id: 5776f46a7cb24475a8e539cc0ba24270\n",
      "hostname: coolo-computer\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.566733717918396\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0089043527841568\n",
      "        model: {}\n",
      "        policy_loss: -0.014431366696953773\n",
      "        total_loss: 516.7924194335938\n",
      "        vf_explained_var: 0.15327689051628113\n",
      "        vf_loss: 516.8029174804688\n",
      "  num_agent_steps_sampled: 13121\n",
      "  num_agent_steps_trained: 13121\n",
      "  num_steps_sampled: 13121\n",
      "  num_steps_trained: 13121\n",
      "iterations_since_restore: 3\n",
      "node_ip: 192.168.1.21\n",
      "num_healthy_workers: 2\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.11666666666667\n",
      "  ram_util_percent: 65.5\n",
      "pid: 17352\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.05810339087404511\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.06983647147471306\n",
      "  mean_inference_ms: 0.6413240702074501\n",
      "  mean_raw_obs_processing_ms: 0.10985519209596978\n",
      "time_since_restore: 12.648873090744019\n",
      "time_this_iter_s: 4.20606255531311\n",
      "time_total_s: 12.648873090744019\n",
      "timers:\n",
      "  learn_throughput: 1328.129\n",
      "  learn_time_ms: 3293.103\n",
      "  load_throughput: 468768.848\n",
      "  load_time_ms: 9.33\n",
      "  sample_throughput: 4857.874\n",
      "  sample_time_ms: 900.325\n",
      "  update_time_ms: 2.192\n",
      "timestamp: 1627256152\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 13121\n",
      "training_iteration: 3\n",
      "\n",
      "Training iteration 3...\n",
      "agent_timesteps_total: 17691\n",
      "custom_metrics: {}\n",
      "date: 2021-07-26_11-35-56\n",
      "done: false\n",
      "episode_len_mean: 70.44\n",
      "episode_media: {}\n",
      "episode_reward_max: 600.0\n",
      "episode_reward_mean: 151.75\n",
      "episode_reward_min: 38.0\n",
      "episodes_this_iter: 8\n",
      "episodes_total: 111\n",
      "experiment_id: 5776f46a7cb24475a8e539cc0ba24270\n",
      "hostname: coolo-computer\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5715048909187317\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005920819006860256\n",
      "        model: {}\n",
      "        policy_loss: -0.011680486612021923\n",
      "        total_loss: 450.81689453125\n",
      "        vf_explained_var: 0.26024141907691956\n",
      "        vf_loss: 450.8258972167969\n",
      "  num_agent_steps_sampled: 17691\n",
      "  num_agent_steps_trained: 17691\n",
      "  num_steps_sampled: 17691\n",
      "  num_steps_trained: 17691\n",
      "iterations_since_restore: 4\n",
      "node_ip: 192.168.1.21\n",
      "num_healthy_workers: 2\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.650000000000006\n",
      "  ram_util_percent: 65.39999999999999\n",
      "pid: 17352\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.058215870413714794\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07000170040180466\n",
      "  mean_inference_ms: 0.6396353993762932\n",
      "  mean_raw_obs_processing_ms: 0.1089911983230135\n",
      "time_since_restore: 16.61829376220703\n",
      "time_this_iter_s: 3.9694206714630127\n",
      "time_total_s: 16.61829376220703\n",
      "timers:\n",
      "  learn_throughput: 1354.066\n",
      "  learn_time_ms: 3266.272\n",
      "  load_throughput: 611688.062\n",
      "  load_time_ms: 7.23\n",
      "  sample_throughput: 5087.315\n",
      "  sample_time_ms: 869.368\n",
      "  update_time_ms: 2.128\n",
      "timestamp: 1627256156\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 17691\n",
      "training_iteration: 4\n",
      "\n",
      "Training iteration 4...\n",
      "agent_timesteps_total: 22027\n",
      "custom_metrics: {}\n",
      "date: 2021-07-26_11-36-00\n",
      "done: false\n",
      "episode_len_mean: 84.01\n",
      "episode_media: {}\n",
      "episode_reward_max: 600.0\n",
      "episode_reward_mean: 186.44\n",
      "episode_reward_min: 38.0\n",
      "episodes_this_iter: 8\n",
      "episodes_total: 119\n",
      "experiment_id: 5776f46a7cb24475a8e539cc0ba24270\n",
      "hostname: coolo-computer\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5418556928634644\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0047820559702813625\n",
      "        model: {}\n",
      "        policy_loss: -0.013792995363473892\n",
      "        total_loss: 375.6260070800781\n",
      "        vf_explained_var: 0.2927820682525635\n",
      "        vf_loss: 375.63763427734375\n",
      "  num_agent_steps_sampled: 22027\n",
      "  num_agent_steps_trained: 22027\n",
      "  num_steps_sampled: 22027\n",
      "  num_steps_trained: 22027\n",
      "iterations_since_restore: 5\n",
      "node_ip: 192.168.1.21\n",
      "num_healthy_workers: 2\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.5\n",
      "  ram_util_percent: 65.4\n",
      "pid: 17352\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.05833611960168171\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07019270896599371\n",
      "  mean_inference_ms: 0.6373934819355938\n",
      "  mean_raw_obs_processing_ms: 0.1080530041401671\n",
      "time_since_restore: 20.24289894104004\n",
      "time_this_iter_s: 3.624605178833008\n",
      "time_total_s: 20.24289894104004\n",
      "timers:\n",
      "  learn_throughput: 1377.943\n",
      "  learn_time_ms: 3197.085\n",
      "  load_throughput: 736012.222\n",
      "  load_time_ms: 5.985\n",
      "  sample_throughput: 5277.04\n",
      "  sample_time_ms: 834.824\n",
      "  update_time_ms: 2.103\n",
      "timestamp: 1627256160\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 22027\n",
      "training_iteration: 5\n",
      "\n",
      "Training iteration 5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 26836\n",
      "custom_metrics: {}\n",
      "date: 2021-07-26_11-36-04\n",
      "done: false\n",
      "episode_len_mean: 97.64\n",
      "episode_media: {}\n",
      "episode_reward_max: 600.0\n",
      "episode_reward_mean: 228.0\n",
      "episode_reward_min: 38.0\n",
      "episodes_this_iter: 8\n",
      "episodes_total: 127\n",
      "experiment_id: 5776f46a7cb24475a8e539cc0ba24270\n",
      "hostname: coolo-computer\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.22499999403953552\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.511968195438385\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006085981149226427\n",
      "        model: {}\n",
      "        policy_loss: -0.008046591654419899\n",
      "        total_loss: 347.3614501953125\n",
      "        vf_explained_var: 0.4089990258216858\n",
      "        vf_loss: 347.3681335449219\n",
      "  num_agent_steps_sampled: 26836\n",
      "  num_agent_steps_trained: 26836\n",
      "  num_steps_sampled: 26836\n",
      "  num_steps_trained: 26836\n",
      "iterations_since_restore: 6\n",
      "node_ip: 192.168.1.21\n",
      "num_healthy_workers: 2\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 44.76666666666666\n",
      "  ram_util_percent: 65.39999999999999\n",
      "pid: 17352\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0585611876794926\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07054113970471443\n",
      "  mean_inference_ms: 0.6351655790815027\n",
      "  mean_raw_obs_processing_ms: 0.10724914614830772\n",
      "time_since_restore: 24.429009199142456\n",
      "time_this_iter_s: 4.186110258102417\n",
      "time_total_s: 24.429009199142456\n",
      "timers:\n",
      "  learn_throughput: 1382.199\n",
      "  learn_time_ms: 3235.906\n",
      "  load_throughput: 870318.891\n",
      "  load_time_ms: 5.139\n",
      "  sample_throughput: 5450.615\n",
      "  sample_time_ms: 820.58\n",
      "  update_time_ms: 2.077\n",
      "timestamp: 1627256164\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 26836\n",
      "training_iteration: 6\n",
      "\n",
      "Training iteration 6...\n",
      "agent_timesteps_total: 31636\n",
      "custom_metrics: {}\n",
      "date: 2021-07-26_11-36-09\n",
      "done: false\n",
      "episode_len_mean: 111.19\n",
      "episode_media: {}\n",
      "episode_reward_max: 600.0\n",
      "episode_reward_mean: 270.76\n",
      "episode_reward_min: 38.0\n",
      "episodes_this_iter: 8\n",
      "episodes_total: 135\n",
      "experiment_id: 5776f46a7cb24475a8e539cc0ba24270\n",
      "hostname: coolo-computer\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.22499999403953552\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5512845516204834\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0012473736423999071\n",
      "        model: {}\n",
      "        policy_loss: -0.0006851491634733975\n",
      "        total_loss: 218.280517578125\n",
      "        vf_explained_var: 0.6134365797042847\n",
      "        vf_loss: 218.28091430664062\n",
      "  num_agent_steps_sampled: 31636\n",
      "  num_agent_steps_trained: 31636\n",
      "  num_steps_sampled: 31636\n",
      "  num_steps_trained: 31636\n",
      "iterations_since_restore: 7\n",
      "node_ip: 192.168.1.21\n",
      "num_healthy_workers: 2\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 44.5\n",
      "  ram_util_percent: 65.39999999999999\n",
      "pid: 17352\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.05908800537154112\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07131022697841403\n",
      "  mean_inference_ms: 0.6359246765799373\n",
      "  mean_raw_obs_processing_ms: 0.10706432129470649\n",
      "time_since_restore: 29.062175989151\n",
      "time_this_iter_s: 4.633166790008545\n",
      "time_total_s: 29.062175989151\n",
      "timers:\n",
      "  learn_throughput: 1373.703\n",
      "  learn_time_ms: 3289.961\n",
      "  load_throughput: 975418.101\n",
      "  load_time_ms: 4.633\n",
      "  sample_throughput: 5331.543\n",
      "  sample_time_ms: 847.677\n",
      "  update_time_ms: 2.09\n",
      "timestamp: 1627256169\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 31636\n",
      "training_iteration: 7\n",
      "\n",
      "Training iteration 7...\n",
      "agent_timesteps_total: 36390\n",
      "custom_metrics: {}\n",
      "date: 2021-07-26_11-36-13\n",
      "done: false\n",
      "episode_len_mean: 124.41\n",
      "episode_media: {}\n",
      "episode_reward_max: 600.0\n",
      "episode_reward_mean: 312.41\n",
      "episode_reward_min: 40.0\n",
      "episodes_this_iter: 8\n",
      "episodes_total: 143\n",
      "experiment_id: 5776f46a7cb24475a8e539cc0ba24270\n",
      "hostname: coolo-computer\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.11249999701976776\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5313270092010498\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008315003477036953\n",
      "        model: {}\n",
      "        policy_loss: -0.004721395205706358\n",
      "        total_loss: 268.59832763671875\n",
      "        vf_explained_var: 0.5771382451057434\n",
      "        vf_loss: 268.60211181640625\n",
      "  num_agent_steps_sampled: 36390\n",
      "  num_agent_steps_trained: 36390\n",
      "  num_steps_sampled: 36390\n",
      "  num_steps_trained: 36390\n",
      "iterations_since_restore: 8\n",
      "node_ip: 192.168.1.21\n",
      "num_healthy_workers: 2\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.72\n",
      "  ram_util_percent: 65.3\n",
      "pid: 17352\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.05968437508667281\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07222212729703596\n",
      "  mean_inference_ms: 0.6373619967901282\n",
      "  mean_raw_obs_processing_ms: 0.10729959507332165\n",
      "time_since_restore: 33.12508535385132\n",
      "time_this_iter_s: 4.062909364700317\n",
      "time_total_s: 33.12508535385132\n",
      "timers:\n",
      "  learn_throughput: 1378.781\n",
      "  learn_time_ms: 3299.111\n",
      "  load_throughput: 1089550.152\n",
      "  load_time_ms: 4.175\n",
      "  sample_throughput: 5491.329\n",
      "  sample_time_ms: 828.351\n",
      "  update_time_ms: 2.051\n",
      "timestamp: 1627256173\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 36390\n",
      "training_iteration: 8\n",
      "\n",
      "Training iteration 8...\n",
      "agent_timesteps_total: 41188\n",
      "custom_metrics: {}\n",
      "date: 2021-07-26_11-36-17\n",
      "done: false\n",
      "episode_len_mean: 137.16\n",
      "episode_media: {}\n",
      "episode_reward_max: 600.0\n",
      "episode_reward_mean: 354.24\n",
      "episode_reward_min: 40.0\n",
      "episodes_this_iter: 8\n",
      "episodes_total: 151\n",
      "experiment_id: 5776f46a7cb24475a8e539cc0ba24270\n",
      "hostname: coolo-computer\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.11249999701976776\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5065061450004578\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004895412363111973\n",
      "        model: {}\n",
      "        policy_loss: -0.005488185677677393\n",
      "        total_loss: 407.1123046875\n",
      "        vf_explained_var: 0.38096290826797485\n",
      "        vf_loss: 407.1172790527344\n",
      "  num_agent_steps_sampled: 41188\n",
      "  num_agent_steps_trained: 41188\n",
      "  num_steps_sampled: 41188\n",
      "  num_steps_trained: 41188\n",
      "iterations_since_restore: 9\n",
      "node_ip: 192.168.1.21\n",
      "num_healthy_workers: 2\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.18333333333333\n",
      "  ram_util_percent: 65.3\n",
      "pid: 17352\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.060262122570697144\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07312223499626605\n",
      "  mean_inference_ms: 0.6380919714519979\n",
      "  mean_raw_obs_processing_ms: 0.10750030493902829\n",
      "time_since_restore: 36.981974363327026\n",
      "time_this_iter_s: 3.856889009475708\n",
      "time_total_s: 36.981974363327026\n",
      "timers:\n",
      "  learn_throughput: 1393.138\n",
      "  learn_time_ms: 3284.99\n",
      "  load_throughput: 1198613.694\n",
      "  load_time_ms: 3.818\n",
      "  sample_throughput: 5638.146\n",
      "  sample_time_ms: 811.693\n",
      "  update_time_ms: 2.008\n",
      "timestamp: 1627256177\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 41188\n",
      "training_iteration: 9\n",
      "\n",
      "Training iteration 9...\n",
      "agent_timesteps_total: 45969\n",
      "custom_metrics: {}\n",
      "date: 2021-07-26_11-36-21\n",
      "done: false\n",
      "episode_len_mean: 150.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 600.0\n",
      "episode_reward_mean: 396.01\n",
      "episode_reward_min: 40.0\n",
      "episodes_this_iter: 8\n",
      "episodes_total: 159\n",
      "experiment_id: 5776f46a7cb24475a8e539cc0ba24270\n",
      "hostname: coolo-computer\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.05624999850988388\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.48164665699005127\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006492635700851679\n",
      "        model: {}\n",
      "        policy_loss: -0.00407270947471261\n",
      "        total_loss: 283.65704345703125\n",
      "        vf_explained_var: 0.5391244888305664\n",
      "        vf_loss: 283.6607360839844\n",
      "  num_agent_steps_sampled: 45969\n",
      "  num_agent_steps_trained: 45969\n",
      "  num_steps_sampled: 45969\n",
      "  num_steps_trained: 45969\n",
      "iterations_since_restore: 10\n",
      "node_ip: 192.168.1.21\n",
      "num_healthy_workers: 2\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.51666666666666\n",
      "  ram_util_percent: 65.36666666666666\n",
      "pid: 17352\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.060826062533874035\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07401371288328391\n",
      "  mean_inference_ms: 0.638300626256358\n",
      "  mean_raw_obs_processing_ms: 0.10766365325016171\n",
      "time_since_restore: 40.96768116950989\n",
      "time_this_iter_s: 3.9857068061828613\n",
      "time_total_s: 40.96768116950989\n",
      "timers:\n",
      "  learn_throughput: 1398.948\n",
      "  learn_time_ms: 3285.969\n",
      "  load_throughput: 1296711.013\n",
      "  load_time_ms: 3.545\n",
      "  sample_throughput: 5753.629\n",
      "  sample_time_ms: 798.957\n",
      "  update_time_ms: 1.97\n",
      "timestamp: 1627256181\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 45969\n",
      "training_iteration: 10\n",
      "\n",
      "Training iteration 10...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 50769\n",
      "custom_metrics: {}\n",
      "date: 2021-07-26_11-36-25\n",
      "done: false\n",
      "episode_len_mean: 162.18\n",
      "episode_media: {}\n",
      "episode_reward_max: 600.0\n",
      "episode_reward_mean: 435.95\n",
      "episode_reward_min: 40.0\n",
      "episodes_this_iter: 8\n",
      "episodes_total: 167\n",
      "experiment_id: 5776f46a7cb24475a8e539cc0ba24270\n",
      "hostname: coolo-computer\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.05624999850988388\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.47925934195518494\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007835951633751392\n",
      "        model: {}\n",
      "        policy_loss: -0.0030298002529889345\n",
      "        total_loss: 295.2467041015625\n",
      "        vf_explained_var: 0.5407967567443848\n",
      "        vf_loss: 295.2492980957031\n",
      "  num_agent_steps_sampled: 50769\n",
      "  num_agent_steps_trained: 50769\n",
      "  num_steps_sampled: 50769\n",
      "  num_steps_trained: 50769\n",
      "iterations_since_restore: 11\n",
      "node_ip: 192.168.1.21\n",
      "num_healthy_workers: 2\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.92\n",
      "  ram_util_percent: 65.4\n",
      "pid: 17352\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06149119950036168\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07495315385374872\n",
      "  mean_inference_ms: 0.6394420682248018\n",
      "  mean_raw_obs_processing_ms: 0.10803923249741733\n",
      "time_since_restore: 44.95867037773132\n",
      "time_this_iter_s: 3.9909892082214355\n",
      "time_total_s: 44.95867037773132\n",
      "timers:\n",
      "  learn_throughput: 1421.768\n",
      "  learn_time_ms: 3271.56\n",
      "  load_throughput: 4512509.975\n",
      "  load_time_ms: 1.031\n",
      "  sample_throughput: 6018.508\n",
      "  sample_time_ms: 772.849\n",
      "  update_time_ms: 1.904\n",
      "timestamp: 1627256185\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 50769\n",
      "training_iteration: 11\n",
      "\n",
      "Training iteration 11...\n",
      "agent_timesteps_total: 55563\n",
      "custom_metrics: {}\n",
      "date: 2021-07-26_11-36-29\n",
      "done: false\n",
      "episode_len_mean: 173.02\n",
      "episode_media: {}\n",
      "episode_reward_max: 600.0\n",
      "episode_reward_mean: 474.02\n",
      "episode_reward_min: 40.0\n",
      "episodes_this_iter: 8\n",
      "episodes_total: 175\n",
      "experiment_id: 5776f46a7cb24475a8e539cc0ba24270\n",
      "hostname: coolo-computer\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.05624999850988388\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.49311724305152893\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00819818302989006\n",
      "        model: {}\n",
      "        policy_loss: -0.005799591541290283\n",
      "        total_loss: 303.8471374511719\n",
      "        vf_explained_var: 0.5279268026351929\n",
      "        vf_loss: 303.8524475097656\n",
      "  num_agent_steps_sampled: 55563\n",
      "  num_agent_steps_trained: 55563\n",
      "  num_steps_sampled: 55563\n",
      "  num_steps_trained: 55563\n",
      "iterations_since_restore: 12\n",
      "node_ip: 192.168.1.21\n",
      "num_healthy_workers: 2\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.449999999999996\n",
      "  ram_util_percent: 65.39999999999999\n",
      "pid: 17352\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06216452425975791\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07589577099860771\n",
      "  mean_inference_ms: 0.6404087330815085\n",
      "  mean_raw_obs_processing_ms: 0.10843577216729709\n",
      "time_since_restore: 48.885926961898804\n",
      "time_this_iter_s: 3.9272565841674805\n",
      "time_total_s: 48.885926961898804\n",
      "timers:\n",
      "  learn_throughput: 1442.205\n",
      "  learn_time_ms: 3276.858\n",
      "  load_throughput: 4555702.43\n",
      "  load_time_ms: 1.037\n",
      "  sample_throughput: 6214.816\n",
      "  sample_time_ms: 760.425\n",
      "  update_time_ms: 1.786\n",
      "timestamp: 1627256189\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 55563\n",
      "training_iteration: 12\n",
      "\n",
      "Training iteration 12...\n",
      "agent_timesteps_total: 60363\n",
      "custom_metrics: {}\n",
      "date: 2021-07-26_11-36-33\n",
      "done: false\n",
      "episode_len_mean: 184.87\n",
      "episode_media: {}\n",
      "episode_reward_max: 600.0\n",
      "episode_reward_mean: 513.17\n",
      "episode_reward_min: 96.0\n",
      "episodes_this_iter: 8\n",
      "episodes_total: 183\n",
      "experiment_id: 5776f46a7cb24475a8e539cc0ba24270\n",
      "hostname: coolo-computer\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.05624999850988388\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.47968417406082153\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0034507960081100464\n",
      "        model: {}\n",
      "        policy_loss: -0.0013590193120762706\n",
      "        total_loss: 203.8675537109375\n",
      "        vf_explained_var: 0.65309739112854\n",
      "        vf_loss: 203.86871337890625\n",
      "  num_agent_steps_sampled: 60363\n",
      "  num_agent_steps_trained: 60363\n",
      "  num_steps_sampled: 60363\n",
      "  num_steps_trained: 60363\n",
      "iterations_since_restore: 13\n",
      "node_ip: 192.168.1.21\n",
      "num_healthy_workers: 2\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.599999999999994\n",
      "  ram_util_percent: 65.39999999999999\n",
      "pid: 17352\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06293980819324224\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07703598336922675\n",
      "  mean_inference_ms: 0.6423536975950762\n",
      "  mean_raw_obs_processing_ms: 0.10920615505483859\n",
      "time_since_restore: 52.809969425201416\n",
      "time_this_iter_s: 3.9240424633026123\n",
      "time_total_s: 52.809969425201416\n",
      "timers:\n",
      "  learn_throughput: 1442.464\n",
      "  learn_time_ms: 3275.09\n",
      "  load_throughput: 4530634.722\n",
      "  load_time_ms: 1.043\n",
      "  sample_throughput: 6435.992\n",
      "  sample_time_ms: 734.028\n",
      "  update_time_ms: 1.795\n",
      "timestamp: 1627256193\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 60363\n",
      "training_iteration: 13\n",
      "\n",
      "Training iteration 13...\n",
      "agent_timesteps_total: 65163\n",
      "custom_metrics: {}\n",
      "date: 2021-07-26_11-36-37\n",
      "done: false\n",
      "episode_len_mean: 194.45\n",
      "episode_media: {}\n",
      "episode_reward_max: 600.0\n",
      "episode_reward_mean: 549.23\n",
      "episode_reward_min: 205.0\n",
      "episodes_this_iter: 8\n",
      "episodes_total: 191\n",
      "experiment_id: 5776f46a7cb24475a8e539cc0ba24270\n",
      "hostname: coolo-computer\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.02812499925494194\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4661180078983307\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0048810564912855625\n",
      "        model: {}\n",
      "        policy_loss: -0.00125264679081738\n",
      "        total_loss: 330.44879150390625\n",
      "        vf_explained_var: 0.5133062601089478\n",
      "        vf_loss: 330.44989013671875\n",
      "  num_agent_steps_sampled: 65163\n",
      "  num_agent_steps_trained: 65163\n",
      "  num_steps_sampled: 65163\n",
      "  num_steps_trained: 65163\n",
      "iterations_since_restore: 14\n",
      "node_ip: 192.168.1.21\n",
      "num_healthy_workers: 2\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.559999999999995\n",
      "  ram_util_percent: 65.4\n",
      "pid: 17352\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06374161632240508\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07824077262126466\n",
      "  mean_inference_ms: 0.6444833495157819\n",
      "  mean_raw_obs_processing_ms: 0.11010328560954072\n",
      "time_since_restore: 56.6910355091095\n",
      "time_this_iter_s: 3.881066083908081\n",
      "time_total_s: 56.6910355091095\n",
      "timers:\n",
      "  learn_throughput: 1449.791\n",
      "  learn_time_ms: 3274.404\n",
      "  load_throughput: 4540131.327\n",
      "  load_time_ms: 1.046\n",
      "  sample_throughput: 6539.353\n",
      "  sample_time_ms: 725.943\n",
      "  update_time_ms: 1.772\n",
      "timestamp: 1627256197\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 65163\n",
      "training_iteration: 14\n",
      "\n",
      "Training iteration 14...\n",
      "agent_timesteps_total: 69963\n",
      "custom_metrics: {}\n",
      "date: 2021-07-26_11-36-41\n",
      "done: false\n",
      "episode_len_mean: 197.98\n",
      "episode_media: {}\n",
      "episode_reward_max: 600.0\n",
      "episode_reward_mean: 572.85\n",
      "episode_reward_min: 256.0\n",
      "episodes_this_iter: 8\n",
      "episodes_total: 199\n",
      "experiment_id: 5776f46a7cb24475a8e539cc0ba24270\n",
      "hostname: coolo-computer\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.01406249962747097\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4474160969257355\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009235464036464691\n",
      "        model: {}\n",
      "        policy_loss: -0.0029982917476445436\n",
      "        total_loss: 274.5031433105469\n",
      "        vf_explained_var: 0.5927852392196655\n",
      "        vf_loss: 274.5060119628906\n",
      "  num_agent_steps_sampled: 69963\n",
      "  num_agent_steps_trained: 69963\n",
      "  num_steps_sampled: 69963\n",
      "  num_steps_trained: 69963\n",
      "iterations_since_restore: 15\n",
      "node_ip: 192.168.1.21\n",
      "num_healthy_workers: 2\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.699999999999996\n",
      "  ram_util_percent: 65.39999999999999\n",
      "pid: 17352\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06420371926488673\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07894211647306629\n",
      "  mean_inference_ms: 0.6432408814428849\n",
      "  mean_raw_obs_processing_ms: 0.11056745722826118\n",
      "time_since_restore: 60.748533487319946\n",
      "time_this_iter_s: 4.057497978210449\n",
      "time_total_s: 60.748533487319946\n",
      "timers:\n",
      "  learn_throughput: 1443.566\n",
      "  learn_time_ms: 3320.665\n",
      "  load_throughput: 4575014.371\n",
      "  load_time_ms: 1.048\n",
      "  sample_throughput: 6629.505\n",
      "  sample_time_ms: 723.071\n",
      "  update_time_ms: 1.732\n",
      "timestamp: 1627256201\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 69963\n",
      "training_iteration: 15\n",
      "\n",
      "Training iteration 15...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 74752\n",
      "custom_metrics: {}\n",
      "date: 2021-07-26_11-36-45\n",
      "done: false\n",
      "episode_len_mean: 199.85\n",
      "episode_media: {}\n",
      "episode_reward_max: 600.0\n",
      "episode_reward_mean: 586.27\n",
      "episode_reward_min: 314.0\n",
      "episodes_this_iter: 8\n",
      "episodes_total: 207\n",
      "experiment_id: 5776f46a7cb24475a8e539cc0ba24270\n",
      "hostname: coolo-computer\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.01406249962747097\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4227916896343231\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00378978974185884\n",
      "        model: {}\n",
      "        policy_loss: -0.002267798176035285\n",
      "        total_loss: 193.90103149414062\n",
      "        vf_explained_var: 0.6970094442367554\n",
      "        vf_loss: 193.9031982421875\n",
      "  num_agent_steps_sampled: 74752\n",
      "  num_agent_steps_trained: 74752\n",
      "  num_steps_sampled: 74752\n",
      "  num_steps_trained: 74752\n",
      "iterations_since_restore: 16\n",
      "node_ip: 192.168.1.21\n",
      "num_healthy_workers: 2\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.28333333333333\n",
      "  ram_util_percent: 65.39999999999999\n",
      "pid: 17352\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06459826220644226\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07957904633562246\n",
      "  mean_inference_ms: 0.6418555923431297\n",
      "  mean_raw_obs_processing_ms: 0.11100479877313785\n",
      "time_since_restore: 64.6953673362732\n",
      "time_this_iter_s: 3.946833848953247\n",
      "time_total_s: 64.6953673362732\n",
      "timers:\n",
      "  learn_throughput: 1450.77\n",
      "  learn_time_ms: 3302.798\n",
      "  load_throughput: 4565832.984\n",
      "  load_time_ms: 1.049\n",
      "  sample_throughput: 6682.785\n",
      "  sample_time_ms: 717.006\n",
      "  update_time_ms: 1.712\n",
      "timestamp: 1627256205\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 74752\n",
      "training_iteration: 16\n",
      "\n",
      "Training iteration 16...\n",
      "agent_timesteps_total: 79536\n",
      "custom_metrics: {}\n",
      "date: 2021-07-26_11-36-49\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 600.0\n",
      "episode_reward_mean: 594.43\n",
      "episode_reward_min: 432.0\n",
      "episodes_this_iter: 8\n",
      "episodes_total: 215\n",
      "experiment_id: 5776f46a7cb24475a8e539cc0ba24270\n",
      "hostname: coolo-computer\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.007031249813735485\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.41992050409317017\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008362730965018272\n",
      "        model: {}\n",
      "        policy_loss: -0.0030011809431016445\n",
      "        total_loss: 208.3903350830078\n",
      "        vf_explained_var: 0.6652249097824097\n",
      "        vf_loss: 208.3932647705078\n",
      "  num_agent_steps_sampled: 79536\n",
      "  num_agent_steps_trained: 79536\n",
      "  num_steps_sampled: 79536\n",
      "  num_steps_trained: 79536\n",
      "iterations_since_restore: 17\n",
      "node_ip: 192.168.1.21\n",
      "num_healthy_workers: 2\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 46.03333333333333\n",
      "  ram_util_percent: 65.46666666666667\n",
      "pid: 17352\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0649050717258377\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08010307549878645\n",
      "  mean_inference_ms: 0.6403321440354789\n",
      "  mean_raw_obs_processing_ms: 0.11138426453087057\n",
      "time_since_restore: 69.25520896911621\n",
      "time_this_iter_s: 4.559841632843018\n",
      "time_total_s: 69.25520896911621\n",
      "timers:\n",
      "  learn_throughput: 1440.83\n",
      "  learn_time_ms: 3324.473\n",
      "  load_throughput: 4672911.606\n",
      "  load_time_ms: 1.025\n",
      "  sample_throughput: 6960.66\n",
      "  sample_time_ms: 688.153\n",
      "  update_time_ms: 1.67\n",
      "timestamp: 1627256209\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 79536\n",
      "training_iteration: 17\n",
      "\n",
      "Training iteration 17...\n",
      "agent_timesteps_total: 84307\n",
      "custom_metrics: {}\n",
      "date: 2021-07-26_11-36-54\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 600.0\n",
      "episode_reward_mean: 598.71\n",
      "episode_reward_min: 567.0\n",
      "episodes_this_iter: 8\n",
      "episodes_total: 223\n",
      "experiment_id: 5776f46a7cb24475a8e539cc0ba24270\n",
      "hostname: coolo-computer\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.007031249813735485\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4091717600822449\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0067301285453140736\n",
      "        model: {}\n",
      "        policy_loss: -0.0029757926240563393\n",
      "        total_loss: 215.3762664794922\n",
      "        vf_explained_var: 0.6588174700737\n",
      "        vf_loss: 215.37916564941406\n",
      "  num_agent_steps_sampled: 84307\n",
      "  num_agent_steps_trained: 84307\n",
      "  num_steps_sampled: 84307\n",
      "  num_steps_trained: 84307\n",
      "iterations_since_restore: 18\n",
      "node_ip: 192.168.1.21\n",
      "num_healthy_workers: 2\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 45.48571428571429\n",
      "  ram_util_percent: 65.39999999999999\n",
      "pid: 17352\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06522694520676332\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08063061130221248\n",
      "  mean_inference_ms: 0.6397692222175727\n",
      "  mean_raw_obs_processing_ms: 0.1118912105794296\n",
      "time_since_restore: 74.14324235916138\n",
      "time_this_iter_s: 4.888033390045166\n",
      "time_total_s: 74.14324235916138\n",
      "timers:\n",
      "  learn_throughput: 1416.271\n",
      "  learn_time_ms: 3383.32\n",
      "  load_throughput: 4625937.135\n",
      "  load_time_ms: 1.036\n",
      "  sample_throughput: 6732.587\n",
      "  sample_time_ms: 711.717\n",
      "  update_time_ms: 1.706\n",
      "timestamp: 1627256214\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 84307\n",
      "training_iteration: 18\n",
      "\n",
      "Training iteration 18...\n",
      "agent_timesteps_total: 89107\n",
      "custom_metrics: {}\n",
      "date: 2021-07-26_11-36-59\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 600.0\n",
      "episode_reward_mean: 598.71\n",
      "episode_reward_min: 567.0\n",
      "episodes_this_iter: 8\n",
      "episodes_total: 231\n",
      "experiment_id: 5776f46a7cb24475a8e539cc0ba24270\n",
      "hostname: coolo-computer\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.007031249813735485\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.38233062624931335\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030489827040582895\n",
      "        model: {}\n",
      "        policy_loss: -0.0029041743837296963\n",
      "        total_loss: 243.11050415039062\n",
      "        vf_explained_var: 0.6312381029129028\n",
      "        vf_loss: 243.11338806152344\n",
      "  num_agent_steps_sampled: 89107\n",
      "  num_agent_steps_trained: 89107\n",
      "  num_steps_sampled: 89107\n",
      "  num_steps_trained: 89107\n",
      "iterations_since_restore: 19\n",
      "node_ip: 192.168.1.21\n",
      "num_healthy_workers: 2\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.65\n",
      "  ram_util_percent: 65.39999999999999\n",
      "pid: 17352\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06541155216792509\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08094321008565787\n",
      "  mean_inference_ms: 0.6382831344193284\n",
      "  mean_raw_obs_processing_ms: 0.1121686199861226\n",
      "time_since_restore: 78.63223958015442\n",
      "time_this_iter_s: 4.488997220993042\n",
      "time_total_s: 78.63223958015442\n",
      "timers:\n",
      "  learn_throughput: 1396.333\n",
      "  learn_time_ms: 3431.775\n",
      "  load_throughput: 4596506.732\n",
      "  load_time_ms: 1.043\n",
      "  sample_throughput: 6596.877\n",
      "  sample_time_ms: 726.389\n",
      "  update_time_ms: 1.712\n",
      "timestamp: 1627256219\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 89107\n",
      "training_iteration: 19\n",
      "\n",
      "Training iteration 19...\n",
      "agent_timesteps_total: 93907\n",
      "custom_metrics: {}\n",
      "date: 2021-07-26_11-37-03\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 600.0\n",
      "episode_reward_mean: 598.74\n",
      "episode_reward_min: 567.0\n",
      "episodes_this_iter: 8\n",
      "episodes_total: 239\n",
      "experiment_id: 5776f46a7cb24475a8e539cc0ba24270\n",
      "hostname: coolo-computer\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0035156249068677425\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.38173848390579224\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004179427400231361\n",
      "        model: {}\n",
      "        policy_loss: -0.00017278137966059148\n",
      "        total_loss: 322.8344421386719\n",
      "        vf_explained_var: 0.5509564876556396\n",
      "        vf_loss: 322.8345642089844\n",
      "  num_agent_steps_sampled: 93907\n",
      "  num_agent_steps_trained: 93907\n",
      "  num_steps_sampled: 93907\n",
      "  num_steps_trained: 93907\n",
      "iterations_since_restore: 20\n",
      "node_ip: 192.168.1.21\n",
      "num_healthy_workers: 2\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 44.871428571428574\n",
      "  ram_util_percent: 65.45714285714287\n",
      "pid: 17352\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06549850867470307\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08112409385334991\n",
      "  mean_inference_ms: 0.6359963456523304\n",
      "  mean_raw_obs_processing_ms: 0.11229541910754022\n",
      "time_since_restore: 83.45249938964844\n",
      "time_this_iter_s: 4.8202598094940186\n",
      "time_total_s: 83.45249938964844\n",
      "timers:\n",
      "  learn_throughput: 1368.552\n",
      "  learn_time_ms: 3502.825\n",
      "  load_throughput: 4343628.109\n",
      "  load_time_ms: 1.104\n",
      "  sample_throughput: 6490.619\n",
      "  sample_time_ms: 738.574\n",
      "  update_time_ms: 1.735\n",
      "timestamp: 1627256223\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 93907\n",
      "training_iteration: 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(\"Training iteration {}...\".format(i))\n",
    "    result=trainer.train()\n",
    "    print(pretty_print(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MultiAgentCartPole(config={\"num_agents\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02279042, -0.02969461, -0.03318278,  0.04450093])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.agents[1].reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
